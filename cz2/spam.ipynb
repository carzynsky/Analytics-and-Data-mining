{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classifier algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE, SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --user matplotlib\n",
    "dataFrame = pd.read_csv('./data/spam.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4789, 463)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4789 entries, 0 to 4788\n",
      "Columns: 463 entries, ACT_NOW to target\n",
      "dtypes: int64(462), object(1)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dataFrame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT_NOW</th>\n",
       "      <th>ADDRESSES_ON_CD</th>\n",
       "      <th>ADULT_SITE</th>\n",
       "      <th>ADVERT_CODE</th>\n",
       "      <th>ADVERT_CODE2</th>\n",
       "      <th>ALL_CAPS_HEADER</th>\n",
       "      <th>ALL_CAP_PORN</th>\n",
       "      <th>ALL_NATURAL</th>\n",
       "      <th>AMATEUR_PORN</th>\n",
       "      <th>AMAZING</th>\n",
       "      <th>...</th>\n",
       "      <th>X_AUTH_WARNING</th>\n",
       "      <th>X_ENC_PRESENT</th>\n",
       "      <th>X_LIBRARY</th>\n",
       "      <th>X_LIST_UNSUBSCRIBE</th>\n",
       "      <th>X_MSMAIL_PRIORITY_HIGH</th>\n",
       "      <th>X_PRECEDENCE_REF</th>\n",
       "      <th>X_PRIORITY_HIGH</th>\n",
       "      <th>X_STORMPOST_TO</th>\n",
       "      <th>X_X_PRESENT</th>\n",
       "      <th>YOUR_INCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315097</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.089883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.074882</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.043315</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464603</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.113055</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.020434</td>\n",
       "      <td>0.138009</td>\n",
       "      <td>0.028892</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.025023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ACT_NOW  ADDRESSES_ON_CD   ADULT_SITE  ADVERT_CODE  ADVERT_CODE2  \\\n",
       "count  4789.000000           4789.0  4789.000000  4789.000000   4789.000000   \n",
       "mean      0.008144              0.0     0.006056     0.000209      0.006682   \n",
       "std       0.089883              0.0     0.077590     0.014450      0.081478   \n",
       "min       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "25%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "50%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "75%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "max       1.000000              0.0     1.000000     1.000000      1.000000   \n",
       "\n",
       "       ALL_CAPS_HEADER  ALL_CAP_PORN  ALL_NATURAL  AMATEUR_PORN      AMAZING  \\\n",
       "count      4789.000000   4789.000000  4789.000000   4789.000000  4789.000000   \n",
       "mean          0.000626      0.005638     0.007308      0.001879     0.002088   \n",
       "std           0.025023      0.074882     0.085185      0.043315     0.045653   \n",
       "min           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "25%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "50%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "75%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "max           1.000000      1.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       ...  X_AUTH_WARNING  X_ENC_PRESENT    X_LIBRARY  X_LIST_UNSUBSCRIBE  \\\n",
       "count  ...     4789.000000    4789.000000  4789.000000         4789.000000   \n",
       "mean   ...        0.315097       0.001044     0.000626            0.012946   \n",
       "std    ...        0.464603       0.032298     0.025023            0.113055   \n",
       "min    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "25%    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "50%    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "75%    ...        1.000000       0.000000     0.000000            0.000000   \n",
       "max    ...        1.000000       1.000000     1.000000            1.000000   \n",
       "\n",
       "       X_MSMAIL_PRIORITY_HIGH  X_PRECEDENCE_REF  X_PRIORITY_HIGH  \\\n",
       "count             4789.000000       4789.000000      4789.000000   \n",
       "mean                 0.009397          0.000418         0.019420   \n",
       "std                  0.096489          0.020434         0.138009   \n",
       "min                  0.000000          0.000000         0.000000   \n",
       "25%                  0.000000          0.000000         0.000000   \n",
       "50%                  0.000000          0.000000         0.000000   \n",
       "75%                  0.000000          0.000000         0.000000   \n",
       "max                  1.000000          1.000000         1.000000   \n",
       "\n",
       "       X_STORMPOST_TO  X_X_PRESENT  YOUR_INCOME  \n",
       "count     4789.000000  4789.000000  4789.000000  \n",
       "mean         0.000835     0.001253     0.000626  \n",
       "std          0.028892     0.035377     0.025023  \n",
       "min          0.000000     0.000000     0.000000  \n",
       "25%          0.000000     0.000000     0.000000  \n",
       "50%          0.000000     0.000000     0.000000  \n",
       "75%          0.000000     0.000000     0.000000  \n",
       "max          1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 462 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is data balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     2949\n",
       "yes    1840\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows=3208, test rows: 1581\n"
     ]
    }
   ],
   "source": [
    "X = dataFrame.drop(['target'], axis=1)\n",
    "y = dataFrame.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=331, test_size=0.33)\n",
    "print(f'Train rows={X_train.shape[0]}, test rows: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_standarized = scaler.transform(X_train) \n",
    "X_test_standarized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9759645793801391\n"
     ]
    }
   ],
   "source": [
    "svm = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "svm.fit(X_train_standarized, y_train)\n",
    "y_prediction_svm = svm.predict(X_test_standarized)\n",
    "svm_score = svm.score(X_test_standarized, y_test)\n",
    "print(f'Score={svm_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=618, fn=25, fp=13, tn=925\n",
      "sensitivity=0.9611, specificity=0.9861\n",
      "FPR=1.3859%, FNR=3.8880%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_svm).ravel()\n",
    "plot_confusion_matrix(svm, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9380139152435167\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_standarized, y_train)\n",
    "y_prediction_knn = knn.predict(X_test_standarized)\n",
    "knn_score = knn.score(X_test_standarized, y_test)\n",
    "print(f'Score={knn_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=555, fn=88, fp=10, tn=928\n",
      "sensitivity=0.8631, specificity=0.9893\n",
      "FPR=1.0661%, FNR=13.6858%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_knn).ravel()\n",
    "plot_confusion_matrix(knn, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9728020240354206\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_prediction_gnb = gnb.predict(X_test)\n",
    "gnb_score = gnb.score(X_test, y_test)\n",
    "print(f'Score={gnb_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=609, fn=34, fp=9, tn=929\n",
      "sensitivity=0.9471, specificity=0.9904\n",
      "FPR=0.9595%, FNR=5.2877%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_gnb).ravel()\n",
    "plot_confusion_matrix(gnb, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9848197343453511\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=1, max_iter=300, solver='adam')\n",
    "mlp.fit(X_train_standarized, y_train)\n",
    "y_prediction_mlp = mlp.predict(X_test_standarized)\n",
    "mlp_score = mlp.score(X_test_standarized, y_test)\n",
    "print(f'Score={mlp_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=628, fn=15, fp=9, tn=929\n",
      "sensitivity=97.6672%, specificity=99.0405%\n",
      "FPR=0.9595%, FNR=2.3328%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp).ravel()\n",
    "plot_confusion_matrix(mlp, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_mlp = round(100*tp/(tp+fn), 4)\n",
    "specificity_mlp = round(100*tn/(fp+tn), 4)\n",
    "print(\"sensitivity={}%, specificity={}%\".format(sensitivity_mlp, specificity_mlp))\n",
    "\n",
    "fpr_mlp = round(100-specificity_mlp, 4)\n",
    "fnr_mlp = round(100-sensitivity_mlp, 4)\n",
    "print(\"FPR={}%, FNR={}%\".format(fpr_mlp, fnr_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9746995572422518\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state=0)\n",
    "decisionTree.fit(X_train_standarized, y_train)\n",
    "y_prediction_decision_tree = decisionTree.predict(X_test_standarized)\n",
    "decision_tree_score = decisionTree.score(X_test_standarized, y_test)\n",
    "print(f'Score={decision_tree_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=622, fn=21, fp=19, tn=919\n",
      "sensitivity=96.7341%, specificity=97.9744%\n",
      "FPR=2.0256%, FNR=3.2659%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_decision_tree).ravel()\n",
    "plot_confusion_matrix(decisionTree, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_dt = round(100*tp/(tp+fn), 4)\n",
    "specificity_dt = round(100*tn/(fp+tn), 4)\n",
    "print(\"sensitivity={}%, specificity={}%\".format(sensitivity_dt, specificity_dt))\n",
    "\n",
    "fpr_dt = round(100-specificity_dt, 4)\n",
    "fnr_dt = round(100-sensitivity_dt, 4)\n",
    "print(\"FPR={}%, FNR={}%\".format(fpr_dt, fnr_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9639468690702088\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "rfc.fit(X_train_standarized, y_train)\n",
    "y_prediction_rfc = rfc.predict(X_test_standarized)\n",
    "rfc_score = rfc.score(X_test_standarized, y_test)\n",
    "print(f'Score={rfc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=591, fn=52, fp=5, tn=933\n",
      "sensitivity=0.9191, specificity=0.9947\n",
      "FPR=0.5330%, FNR=8.0871%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_rfc).ravel()\n",
    "plot_confusion_matrix(rfc, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9772296015180265\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train_standarized, y_train)\n",
    "y_prediction_lr = lr.predict(X_test_standarized)\n",
    "lr_score = lr.score(X_test_standarized, y_test)\n",
    "print(f'Score={lr_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=620, fn=23, fp=13, tn=925\n",
      "sensitivity=0.9642, specificity=0.9861\n",
      "FPR=1.3859%, FNR=3.5770%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_lr).ravel()\n",
    "plot_confusion_matrix(lr, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classifier parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default MLP has solver 'adam'. \n",
    "The solver for weight optimization.\n",
    "* â€˜lbfgsâ€™ is an optimizer in the family of quasi-Newton methods.\n",
    "* â€˜sgdâ€™ refers to stochastic gradient descent.\n",
    "* â€˜adamâ€™ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "\n",
    "Note: The default solver â€˜adamâ€™ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, â€˜lbfgsâ€™ can converge faster and perform better.\n",
    "(source: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with lbfgs solver=0.978494623655914 (-0.006325110689437086)\n",
      "tp=625, fn=18, fp=16, tn=922\n",
      "sensitivity=97.2006% (-0.4666%), specificity=98.2942% (-0.7463%)\n",
      "lbfgs solver: FPR=1.7058% (+0.7463%), FNR=2.7994% (+0.4666%)\n"
     ]
    }
   ],
   "source": [
    "# solver lbfgs\n",
    "mlp_lbfgs = MLPClassifier(random_state=1, max_iter=300, solver='lbfgs')\n",
    "mlp_lbfgs.fit(X_train_standarized, y_train)\n",
    "y_prediction_mlp_lbfgs = mlp_lbfgs.predict(X_test_standarized)\n",
    "mlp_lbfgs_score = mlp_lbfgs.score(X_test_standarized, y_test)\n",
    "mlp_score_diff = mlp_lbfgs_score-mlp_score\n",
    "print(f'Score with lbfgs solver={mlp_lbfgs_score} ({mlp_score_diff:+})')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_lbfgs).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_mlp_lbfgs = round(100*tp/(tp+fn), 4)\n",
    "specificity_mlp_lbfgs = round(100*tn/(fp+tn), 4)\n",
    "sensitivity_mlp_diff = round(sensitivity_mlp_lbfgs - sensitivity_mlp, 4)\n",
    "specificity_mlp_diff = round(specificity_mlp_lbfgs - specificity_mlp, 4)\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_mlp_lbfgs, sensitivity_mlp_diff, specificity_mlp_lbfgs, specificity_mlp_diff))\n",
    "\n",
    "fpr_mlp_lbfgs = round(100-specificity_mlp_lbfgs, 4)\n",
    "fnr_mlp_lbfgs = round(100-sensitivity_mlp_lbfgs, 4)\n",
    "fpr_mlp_diff = round(fpr_mlp_lbfgs - fpr_mlp, 4)\n",
    "fnr_mlp_diff = round(fnr_mlp_lbfgs - fnr_mlp, 4)\n",
    "print(\"lbfgs solver: FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_lbfgs, fpr_mlp_diff, fnr_mlp_lbfgs, fnr_mlp_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with sgd solver=0.9791271347248577 (-0.005692599620493399)\n",
      "tp=619, fn=24, fp=9, tn=929\n",
      "sensitivity=96.2675% (-1.3997%), specificity=99.0405% (+0.0%)\n",
      "sgd solver: FPR=0.9595% (+0.0%), FNR=3.7325% (+1.3997%)\n"
     ]
    }
   ],
   "source": [
    "# sgd\n",
    "mlp_sgd = MLPClassifier(random_state=1, max_iter=300, solver='sgd')\n",
    "mlp_sgd.fit(X_train_standarized, y_train)\n",
    "y_prediction_mlp_sgd = mlp_sgd.predict(X_test_standarized)\n",
    "mlp_sgd_score = mlp_sgd.score(X_test_standarized, y_test)\n",
    "mlp_score_diff = mlp_sgd_score-mlp_score\n",
    "print(f'Score with sgd solver={mlp_sgd_score} ({mlp_score_diff:+})')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_sgd).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_mlp_sgd = round(100*tp/(tp+fn), 4)\n",
    "specificity_mlp_sgd= round(100*tn/(fp+tn), 4)\n",
    "sensitivity_mlp_diff = round(sensitivity_mlp_sgd - sensitivity_mlp, 4)\n",
    "specificity_mlp_diff = round(specificity_mlp_sgd - specificity_mlp, 4)\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_mlp_sgd, sensitivity_mlp_diff, specificity_mlp_sgd, specificity_mlp_diff))\n",
    "\n",
    "fpr_mlp_sgd = round(100-specificity_mlp_sgd, 4)\n",
    "fnr_mlp_sgd = round(100-sensitivity_mlp_sgd, 4)\n",
    "fpr_mlp_diff = round(fpr_mlp_sgd - fpr_mlp, 4)\n",
    "fnr_mlp_diff = round(fnr_mlp_sgd - fnr_mlp, 4)\n",
    "print(\"sgd solver: FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_sgd, fpr_mlp_diff, fnr_mlp_sgd, fnr_mlp_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layers and number of neurons\n",
    "By default there is 1 hidden layer with 100 neurons. For tests hidden_layer_neuron_numbers contains numbers of neurons in hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 hidden layer\n",
    "hidden_layer_neuron_numbers = [8, 16, 32, 40, 50, 64, 100, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Number of neurons in hidden layer=8\n",
      "Score=0.978494623655914 (-0.006325110689437086)\n",
      "tp=617, fn=26, fp=8, tn=930\n",
      "sensitivity=95.9565% (-1.7107%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=4.0435% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=16\n",
      "Score=0.9791271347248577 (-0.005692599620493399)\n",
      "tp=618, fn=25, fp=8, tn=930\n",
      "sensitivity=96.112% (-1.5552%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=3.888% (+1.5552%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=32\n",
      "Score=0.9778621125869703 (-0.006957621758380772)\n",
      "tp=616, fn=27, fp=8, tn=930\n",
      "sensitivity=95.8009% (-1.8663%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=4.1991% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=40\n",
      "Score=0.9797596457938014 (-0.005060088551549713)\n",
      "tp=621, fn=22, fp=10, tn=928\n",
      "sensitivity=96.5785% (-1.0887%), specificity=98.9339% (-0.1066%)\n",
      "FPR=1.0661% (+0.1066%), FNR=3.4215% (+1.0887%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=50\n",
      "Score=0.9797596457938014 (-0.005060088551549713)\n",
      "tp=619, fn=24, fp=8, tn=930\n",
      "sensitivity=96.2675% (-1.3997%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=3.7325% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=64\n",
      "Score=0.9797596457938014 (-0.005060088551549713)\n",
      "tp=619, fn=24, fp=8, tn=930\n",
      "sensitivity=96.2675% (-1.3997%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=3.7325% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=100\n",
      "Score=0.9791271347248577 (-0.005692599620493399)\n",
      "tp=619, fn=24, fp=9, tn=929\n",
      "sensitivity=96.2675% (-1.3997%), specificity=99.0405% (+0.0%)\n",
      "FPR=0.9595% (+0.0%), FNR=3.7325% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=128\n",
      "Score=0.9772296015180265 (-0.007590132827324569)\n",
      "tp=620, fn=23, fp=13, tn=925\n",
      "sensitivity=96.423% (-1.2442%), specificity=98.6141% (-0.4264%)\n",
      "FPR=1.3859% (+0.4264%), FNR=3.577% (+1.2442%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=256\n",
      "Score=0.9803921568627451 (-0.004427577482606027)\n",
      "tp=620, fn=23, fp=8, tn=930\n",
      "sensitivity=96.423% (-1.2442%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=3.577% (+1.2442%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for neurons in hidden_layer_neuron_numbers:\n",
    "    print('*'*20)\n",
    "    print(f'Number of neurons in hidden layer={neurons}')\n",
    "\n",
    "    # mlp\n",
    "    mlp_hidden_layer_test = MLPClassifier(random_state=1, max_iter=4000, hidden_layer_sizes=(neurons), solver='sgd')\n",
    "    mlp_hidden_layer_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_mlp_hidden_layer_test = mlp_hidden_layer_test.predict(X_test_standarized)\n",
    "    mlp_hidden_layer_test_score = mlp_hidden_layer_test.score(X_test_standarized, y_test)\n",
    "    mlp_score_diff = mlp_hidden_layer_test_score - mlp_score\n",
    "    print(f'Score={mlp_hidden_layer_test_score} ({mlp_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_hidden_layer_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_hidden_layer_test = round(100*tp/(tp+fn), 4)\n",
    "    specificity_mlp_hidden_layer_test = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_mlp_diff = round(sensitivity_mlp_hidden_layer_test - sensitivity_mlp, 4)\n",
    "    specificity_mlp_diff = round(specificity_mlp_hidden_layer_test - specificity_mlp, 4)\n",
    "    print(f'sensitivity={sensitivity_mlp_hidden_layer_test}% ({sensitivity_mlp_diff:+}%), specificity={specificity_mlp_hidden_layer_test}% ({specificity_mlp_diff:+}%)')\n",
    "    \n",
    "    fpr_mlp_hidden_layer_test = round(100-specificity_mlp_hidden_layer_test, 4)\n",
    "    fnr_mlp_hidden_layer_test  = round(100-sensitivity_mlp_hidden_layer_test, 4)\n",
    "    fpr_mlp_diff = round(fpr_mlp_hidden_layer_test - fpr_mlp, 4)\n",
    "    fnr_mlp_diff = round(fnr_mlp_hidden_layer_test - fnr_mlp, 4)\n",
    "    print(f'FPR={fpr_mlp_hidden_layer_test}% ({fpr_mlp_diff:+}%), FNR={fnr_mlp_hidden_layer_test}% ({fnr_mlp_diff:+}%)')\n",
    "    print(' '*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning_rate schedule for weight updates. (By default 'constant', only used when solver is 'sgd')\n",
    "* â€˜constantâ€™ is a constant learning rate given by â€˜learning_rate_initâ€™.\n",
    "\n",
    "* â€˜invscalingâ€™ gradually decreases the learning rate at each time step â€˜tâ€™ using an inverse scaling exponent of â€˜power_tâ€™. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "\n",
    "* â€˜adaptiveâ€™ keeps the learning rate constant to â€˜learning_rate_initâ€™ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if â€˜early_stoppingâ€™ is on, the current learning rate is divided by 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate - invscaling\n",
      "********************\n",
      "Number of neurons in hidden layer=8\n",
      "Score=0.7356103731815307 (-0.24920936116382042)\n",
      "tp=247, fn=396, fp=22, tn=916\n",
      "sensitivity=38.4137% (-59.2535%), specificity=97.6546% (-1.3859%)\n",
      "FPR=2.3454% (+1.3859%), FNR=61.5863% (+59.2535%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=16\n",
      "Score=0.5825426944971537 (-0.4022770398481974)\n",
      "tp=444, fn=199, fp=461, tn=477\n",
      "sensitivity=69.0513% (-28.6159%), specificity=50.8529% (-48.1876%)\n",
      "FPR=49.1471% (+48.1876%), FNR=30.9487% (+28.6159%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=32\n"
     ]
    }
   ],
   "source": [
    "# Learning rate - invscaling\n",
    "print('Learning rate - invscaling')\n",
    "\n",
    "for neurons in hidden_layer_neuron_numbers:\n",
    "    print('*'*20)\n",
    "    print(f'Number of neurons in hidden layer={neurons}')\n",
    "    # mlp\n",
    "    mlp_hidden_layer_test = MLPClassifier(random_state=1, max_iter=4000, hidden_layer_sizes=(neurons), solver='sgd', learning_rate='invscaling')\n",
    "    mlp_hidden_layer_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_mlp_hidden_layer_test = mlp_hidden_layer_test.predict(X_test_standarized)\n",
    "    mlp_hidden_layer_test_score = mlp_hidden_layer_test.score(X_test_standarized, y_test)\n",
    "    mlp_score_diff = mlp_hidden_layer_test_score - mlp_score\n",
    "    print(f'Score={mlp_hidden_layer_test_score} ({mlp_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_hidden_layer_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_hidden_layer_test = round(100*tp/(tp+fn), 4)\n",
    "    specificity_mlp_hidden_layer_test = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_mlp_diff = round(sensitivity_mlp_hidden_layer_test - sensitivity_mlp, 4)\n",
    "    specificity_mlp_diff = round(specificity_mlp_hidden_layer_test - specificity_mlp, 4)\n",
    "    print(f'sensitivity={sensitivity_mlp_hidden_layer_test}% ({sensitivity_mlp_diff:+}%), specificity={specificity_mlp_hidden_layer_test}% ({specificity_mlp_diff:+}%)')\n",
    "    \n",
    "    fpr_mlp_hidden_layer_test = round(100-specificity_mlp_hidden_layer_test, 4)\n",
    "    fnr_mlp_hidden_layer_test  = round(100-sensitivity_mlp_hidden_layer_test, 4)\n",
    "    fpr_mlp_diff = round(fpr_mlp_hidden_layer_test - fpr_mlp, 4)\n",
    "    fnr_mlp_diff = round(fnr_mlp_hidden_layer_test - fnr_mlp, 4)\n",
    "    print(f'FPR={fpr_mlp_hidden_layer_test}% ({fpr_mlp_diff:+}%), FNR={fnr_mlp_hidden_layer_test}% ({fnr_mlp_diff:+}%)')\n",
    "    print(' '*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate - adaptive\n",
      "********************\n",
      "Number of neurons in hidden layer=8\n",
      "Score=0.978494623655914 (-0.006325110689437086)\n",
      "tp=617, fn=26, fp=8, tn=930\n",
      "sensitivity=95.9565% (-1.7107%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=4.0435% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=16\n",
      "Score=0.9791271347248577 (-0.005692599620493399)\n",
      "tp=618, fn=25, fp=8, tn=930\n",
      "sensitivity=96.112% (-1.5552%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=3.888% (+1.5552%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=32\n",
      "Score=0.9778621125869703 (-0.006957621758380772)\n",
      "tp=616, fn=27, fp=8, tn=930\n",
      "sensitivity=95.8009% (-1.8663%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=4.1991% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=40\n",
      "Score=0.9797596457938014 (-0.005060088551549713)\n",
      "tp=621, fn=22, fp=10, tn=928\n",
      "sensitivity=96.5785% (-1.0887%), specificity=98.9339% (-0.1066%)\n",
      "FPR=1.0661% (+0.1066%), FNR=3.4215% (+1.0887%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=50\n",
      "Score=0.9797596457938014 (-0.005060088551549713)\n",
      "tp=619, fn=24, fp=8, tn=930\n",
      "sensitivity=96.2675% (-1.3997%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=3.7325% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=64\n",
      "Score=0.9797596457938014 (-0.005060088551549713)\n",
      "tp=619, fn=24, fp=8, tn=930\n",
      "sensitivity=96.2675% (-1.3997%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=3.7325% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=100\n",
      "Score=0.9791271347248577 (-0.005692599620493399)\n",
      "tp=619, fn=24, fp=9, tn=929\n",
      "sensitivity=96.2675% (-1.3997%), specificity=99.0405% (+0.0%)\n",
      "FPR=0.9595% (+0.0%), FNR=3.7325% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=128\n",
      "Score=0.9772296015180265 (-0.007590132827324569)\n",
      "tp=620, fn=23, fp=13, tn=925\n",
      "sensitivity=96.423% (-1.2442%), specificity=98.6141% (-0.4264%)\n",
      "FPR=1.3859% (+0.4264%), FNR=3.577% (+1.2442%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer=256\n",
      "Score=0.9803921568627451 (-0.004427577482606027)\n",
      "tp=620, fn=23, fp=8, tn=930\n",
      "sensitivity=96.423% (-1.2442%), specificity=99.1471% (+0.1066%)\n",
      "FPR=0.8529% (-0.1066%), FNR=3.577% (+1.2442%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "# Learning rate - adaptive\n",
    "print('Learning rate - adaptive')\n",
    "\n",
    "for neurons in hidden_layer_neuron_numbers:\n",
    "    print('*'*20)\n",
    "    print(f'Number of neurons in hidden layer={neurons}')\n",
    "    # mlp\n",
    "    mlp_hidden_layer_test = MLPClassifier(random_state=1, max_iter=4000, hidden_layer_sizes=(neurons), solver='sgd', learning_rate='adaptive')\n",
    "    mlp_hidden_layer_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_mlp_hidden_layer_test = mlp_hidden_layer_test.predict(X_test_standarized)\n",
    "    mlp_hidden_layer_test_score = mlp_hidden_layer_test.score(X_test_standarized, y_test)\n",
    "    mlp_score_diff = mlp_hidden_layer_test_score - mlp_score\n",
    "    print(f'Score={mlp_hidden_layer_test_score} ({mlp_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_hidden_layer_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_hidden_layer_test = round(100*tp/(tp+fn), 4)\n",
    "    specificity_mlp_hidden_layer_test = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_mlp_diff = round(sensitivity_mlp_hidden_layer_test - sensitivity_mlp, 4)\n",
    "    specificity_mlp_diff = round(specificity_mlp_hidden_layer_test - specificity_mlp, 4)\n",
    "    print(f'sensitivity={sensitivity_mlp_hidden_layer_test}% ({sensitivity_mlp_diff:+}%), specificity={specificity_mlp_hidden_layer_test}% ({specificity_mlp_diff:+}%)')\n",
    "    \n",
    "    fpr_mlp_hidden_layer_test = round(100-specificity_mlp_hidden_layer_test, 4)\n",
    "    fnr_mlp_hidden_layer_test  = round(100-sensitivity_mlp_hidden_layer_test, 4)\n",
    "    fpr_mlp_diff = round(fpr_mlp_hidden_layer_test - fpr_mlp, 4)\n",
    "    fnr_mlp_diff = round(fnr_mlp_hidden_layer_test - fnr_mlp, 4)\n",
    "    print(f'FPR={fpr_mlp_hidden_layer_test}% ({fpr_mlp_diff:+}%), FNR={fnr_mlp_hidden_layer_test}% ({fnr_mlp_diff:+}%)')\n",
    "    print(' '*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 layers in hidden layer with sgd solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers_neuron_numbers = [(16, 32), (32, 64), (64, 128), (128, 256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "hidden layer sizes=(16, 32)\n",
      "Score=0.978494623655914 (-0.006325110689437086)\n",
      "tp=618, fn=25, fp=9, tn=929\n",
      "sensitivity=96.112% (-1.5552%), specificity=99.0405% (+0.0%)\n",
      "FPR=0.9595% (+0.0%), FNR=3.888% (+1.5552%)\n",
      "                    \n",
      "********************\n",
      "hidden layer sizes=(32, 64)\n",
      "Score=0.978494623655914 (-0.006325110689437086)\n",
      "tp=618, fn=25, fp=9, tn=929\n",
      "sensitivity=96.112% (-1.5552%), specificity=99.0405% (+0.0%)\n",
      "FPR=0.9595% (+0.0%), FNR=3.888% (+1.5552%)\n",
      "                    \n",
      "********************\n",
      "hidden layer sizes=(64, 128)\n",
      "Score=0.978494623655914 (-0.006325110689437086)\n",
      "tp=620, fn=23, fp=11, tn=927\n",
      "sensitivity=96.423% (-1.2442%), specificity=98.8273% (-0.2132%)\n",
      "FPR=1.1727% (+0.2132%), FNR=3.577% (+1.2442%)\n",
      "                    \n",
      "********************\n",
      "hidden layer sizes=(128, 256)\n",
      "Score=0.9797596457938014 (-0.005060088551549713)\n",
      "tp=623, fn=20, fp=12, tn=926\n",
      "sensitivity=96.8896% (-0.7776%), specificity=98.7207% (-0.3198%)\n",
      "FPR=1.2793% (+0.3198%), FNR=3.1104% (+0.7776%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for hidden_layer_sizes in hidden_layers_neuron_numbers:\n",
    "    print('*'*20)\n",
    "    print(f'hidden layer sizes={hidden_layer_sizes}')\n",
    "    # mlp\n",
    "    mlp_hidden_layer_test = MLPClassifier(random_state=1, max_iter=4000, hidden_layer_sizes=(hidden_layer_sizes), solver='sgd')\n",
    "    mlp_hidden_layer_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_mlp_hidden_layer_test = mlp_hidden_layer_test.predict(X_test_standarized)\n",
    "    mlp_hidden_layer_test_score = mlp_hidden_layer_test.score(X_test_standarized, y_test)\n",
    "    mlp_score_diff = mlp_hidden_layer_test_score - mlp_score\n",
    "    print(f'Score={mlp_hidden_layer_test_score} ({mlp_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_hidden_layer_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_hidden_layer_test = round(100*tp/(tp+fn), 4)\n",
    "    specificity_mlp_hidden_layer_test = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_mlp_diff = round(sensitivity_mlp_hidden_layer_test - sensitivity_mlp, 4)\n",
    "    specificity_mlp_diff = round(specificity_mlp_hidden_layer_test - specificity_mlp, 4)\n",
    "    print(f'sensitivity={sensitivity_mlp_hidden_layer_test}% ({sensitivity_mlp_diff:+}%), specificity={specificity_mlp_hidden_layer_test}% ({specificity_mlp_diff:+}%)')\n",
    "    \n",
    "    fpr_mlp_hidden_layer_test = round(100-specificity_mlp_hidden_layer_test, 4)\n",
    "    fnr_mlp_hidden_layer_test  = round(100-sensitivity_mlp_hidden_layer_test, 4)\n",
    "    fpr_mlp_diff = round(fpr_mlp_hidden_layer_test - fpr_mlp, 4)\n",
    "    fnr_mlp_diff = round(fnr_mlp_hidden_layer_test - fnr_mlp, 4)\n",
    "    print(f'FPR={fpr_mlp_hidden_layer_test}% ({fpr_mlp_diff:+}%), FNR={fnr_mlp_hidden_layer_test}% ({fnr_mlp_diff:+}%)')\n",
    "    print(' '*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum depth\n",
    "max_depth : int, default=None\n",
    "\n",
    "The maximum depth of the tree. \n",
    "If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "max_depth=2\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=581, fn=62, fp=96, tn=842\n",
      "sensitivity=90.3577% (-6.3764%), specificity=89.7655% (-8.2089%)\n",
      "FPR=10.2345% (+8.2089%), FNR=9.6423% (+6.3764%)\n",
      "********************\n",
      "max_depth=4\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=539, fn=104, fp=2, tn=936\n",
      "sensitivity=83.8258% (-12.9083%), specificity=99.7868% (+1.8124%)\n",
      "FPR=0.2132% (-1.8124%), FNR=16.1742% (+12.9083%)\n",
      "********************\n",
      "max_depth=6\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=586, fn=57, fp=3, tn=935\n",
      "sensitivity=91.1353% (-5.5988%), specificity=99.6802% (+1.7058%)\n",
      "FPR=0.3198% (-1.7058%), FNR=8.8647% (+5.5988%)\n",
      "********************\n",
      "max_depth=8\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=608, fn=35, fp=4, tn=934\n",
      "sensitivity=94.5568% (-2.1773%), specificity=99.5736% (+1.5992%)\n",
      "FPR=0.4264% (-1.5992%), FNR=5.4432% (+2.1773%)\n",
      "********************\n",
      "max_depth=10\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=610, fn=33, fp=3, tn=935\n",
      "sensitivity=94.8678% (-1.8663%), specificity=99.6802% (+1.7058%)\n",
      "FPR=0.3198% (-1.7058%), FNR=5.1322% (+1.8663%)\n",
      "********************\n",
      "max_depth=12\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=610, fn=33, fp=5, tn=933\n",
      "sensitivity=94.8678% (-1.8663%), specificity=99.467% (+1.4926%)\n",
      "FPR=0.533% (-1.4926%), FNR=5.1322% (+1.8663%)\n",
      "********************\n",
      "max_depth=14\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=616, fn=27, fp=6, tn=932\n",
      "sensitivity=95.8009% (-0.9332%), specificity=99.3603% (+1.3859%)\n",
      "FPR=0.6397% (-1.3859%), FNR=4.1991% (+0.9332%)\n",
      "********************\n",
      "max_depth=16\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=618, fn=25, fp=8, tn=930\n",
      "sensitivity=96.112% (-0.6221%), specificity=99.1471% (+1.1727%)\n",
      "FPR=0.8529% (-1.1727%), FNR=3.888% (+0.6221%)\n",
      "********************\n",
      "max_depth=18\n",
      "Score=0.9746995572422518 (+0.0)\n",
      "tp=621, fn=22, fp=10, tn=928\n",
      "sensitivity=96.5785% (-0.1556%), specificity=98.9339% (+0.9595%)\n",
      "FPR=1.0661% (-0.9595%), FNR=3.4215% (+0.1556%)\n"
     ]
    }
   ],
   "source": [
    "for max_depth in range(0, 20, 2):\n",
    "    if(max_depth == 0):\n",
    "        continue\n",
    "    \n",
    "    print('*'*20)\n",
    "    print(f'max_depth={max_depth}')\n",
    "\n",
    "    # decision tree\n",
    "    decisionTree_md_test = DecisionTreeClassifier(random_state=0, max_depth=max_depth)\n",
    "    decisionTree_md_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_decision_tree_md_test = decisionTree_md_test.predict(X_test_standarized)\n",
    "    decision_tree_score_md = decisionTree.score(X_test_standarized, y_test)\n",
    "    decision_tree_score_diff = decision_tree_score_md - decision_tree_score\n",
    "    print(f'Score={decision_tree_score_md} ({decision_tree_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_decision_tree_md_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_dt_md = round(100*tp/(tp+fn), 4)\n",
    "    specificity_dt_md = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_dt_diff = round(sensitivity_dt_md - sensitivity_dt, 4)\n",
    "    specificity_dt_diff = round(specificity_dt_md - specificity_dt, 4)\n",
    "    print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_md, sensitivity_dt_diff, specificity_dt_md, specificity_dt_diff))\n",
    "\n",
    "    fpr_dt_md = round(100-specificity_dt_md, 4)\n",
    "    fnr_dt_md = round(100-sensitivity_dt_md, 4)\n",
    "    fpr_dt_diff = round(fpr_dt_md - fpr_dt, 4)\n",
    "    fnr_dt_diff = round(fnr_dt_md - fnr_dt, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_md, fpr_dt_diff, fnr_dt_md, fnr_dt_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to achieve FPR <= 0.5% but at the same time we don't want to increase FNR too much, from above tests the best result might be for max_depth = 10:\n",
    "\n",
    "* max_depth=10\n",
    "* Score=0.9746995572422518 (+0.0)\n",
    "* tp=610, fn=33, fp=3, tn=935\n",
    "* sensitivity=94.8678% (-1.8663%), specificity=99.6802% (+1.7058%)\n",
    "* FPR=0.3198% (-1.7058%), FNR=5.1322% (+1.8663%)\n",
    "\n",
    "FPR is reduced to 0.3198% (-1.7058%), FNR increased to 5.1322% (+1.8663%). In result we reduced the amount of 'good' mails being classified as spam, but at the same time classifier accepts more spam than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 RFE - Recursive feature elimination\n",
    "Feature ranking with recursive feature elimination.\n",
    "\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4789, 463)\n"
     ]
    }
   ],
   "source": [
    "# data size\n",
    "print(dataFrame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE with Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "n_features=50\n",
      "Score=0.9797596457938014 (+0.005060088551549602)\n",
      "tp=621, fn=22, fp=10, tn=928\n",
      "sensitivity=96.5785% (-0.1556%), specificity=98.9339% (+0.9595%)\n",
      "FPR=1.0661% (-0.9595%), FNR=3.4215% (+0.1556%)\n",
      "                    \n",
      "********************\n",
      "n_features=70\n",
      "Score=0.9753320683111955 (+0.0006325110689436864)\n",
      "tp=622, fn=21, fp=18, tn=920\n",
      "sensitivity=96.7341% (+0.0%), specificity=98.081% (+0.1066%)\n",
      "FPR=1.919% (-0.1066%), FNR=3.2659% (+0.0%)\n",
      "                    \n",
      "********************\n",
      "n_features=100\n",
      "Score=0.9759645793801391 (+0.0012650221378873727)\n",
      "tp=620, fn=23, fp=15, tn=923\n",
      "sensitivity=96.423% (-0.3111%), specificity=98.4009% (+0.4265%)\n",
      "FPR=1.5991% (-0.4265%), FNR=3.577% (+0.3111%)\n",
      "                    \n",
      "********************\n",
      "n_features=150\n",
      "Score=0.9765970904490828 (+0.001897533206831059)\n",
      "tp=622, fn=21, fp=16, tn=922\n",
      "sensitivity=96.7341% (+0.0%), specificity=98.2942% (+0.3198%)\n",
      "FPR=1.7058% (-0.3198%), FNR=3.2659% (+0.0%)\n",
      "                    \n",
      "********************\n",
      "n_features=200\n",
      "Score=0.9753320683111955 (+0.0006325110689436864)\n",
      "tp=622, fn=21, fp=18, tn=920\n",
      "sensitivity=96.7341% (+0.0%), specificity=98.081% (+0.1066%)\n",
      "FPR=1.919% (-0.1066%), FNR=3.2659% (+0.0%)\n",
      "                    \n",
      "********************\n",
      "n_features=300\n",
      "Score=0.9759645793801391 (+0.0012650221378873727)\n",
      "tp=623, fn=20, fp=18, tn=920\n",
      "sensitivity=96.8896% (+0.1555%), specificity=98.081% (+0.1066%)\n",
      "FPR=1.919% (-0.1066%), FNR=3.1104% (-0.1555%)\n",
      "                    \n",
      "********************\n",
      "n_features=400\n",
      "Score=0.9753320683111955 (+0.0006325110689436864)\n",
      "tp=622, fn=21, fp=18, tn=920\n",
      "sensitivity=96.7341% (+0.0%), specificity=98.081% (+0.1066%)\n",
      "FPR=1.919% (-0.1066%), FNR=3.2659% (+0.0%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "# take 200 most informative features\n",
    "n_features_list = [50, 70, 100, 150, 200, 300, 400]\n",
    "\n",
    "for n_features in n_features_list:\n",
    "    print('*'*20)\n",
    "    print(f'n_features={n_features}')\n",
    "    \n",
    "    # decision tree\n",
    "    decisionTree_with_rfe = DecisionTreeClassifier()\n",
    "    rfe = RFE(estimator=decisionTree_with_rfe, n_features_to_select=n_features, step=10)\n",
    "    rfe = rfe.fit(X_train_standarized, y_train)\n",
    "    y_prediction_rfe = rfe.predict(X_test_standarized)\n",
    "\n",
    "    # compare score\n",
    "    decisionTree_with_rfe_score = rfe.score(X_test_standarized, y_test)\n",
    "    decisionTree_score_diff = decisionTree_with_rfe_score - decision_tree_score\n",
    "    print(f'Score={decisionTree_with_rfe_score} ({decisionTree_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_rfe).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_dt_rfe = round(100*tp/(tp+fn), 4)\n",
    "    specificity_dt_rfe = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_dt_diff = round(sensitivity_dt_rfe - sensitivity_dt, 4)\n",
    "    specificity_dt_diff = round(specificity_dt_rfe - specificity_dt, 4)\n",
    "    print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_rfe, sensitivity_dt_diff, specificity_dt_rfe, specificity_dt_diff))\n",
    "\n",
    "    fpr_dt_rfe = round(100-specificity_dt_rfe, 4)\n",
    "    fnr_dt_rfe = round(100-sensitivity_dt_rfe, 4)\n",
    "    fpr_dt_diff = round(fpr_dt_rfe - fpr_dt, 4)\n",
    "    fnr_dt_diff = round(fnr_dt_rfe - fnr_dt, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_rfe, fpr_dt_diff, fnr_dt_rfe, fnr_dt_diff))\n",
    "    print(' '*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Univariate feature selection - SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestFeaturesList = [50, 70, 100, 150, 200, 300, 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Best features=50\n",
      "Score=0.9778621125869703 (-0.006957621758380772)\n",
      "tp=620, fn=23, fp=12, tn=926\n",
      "sensitivity=0.9642 (-96.703), specificity=0.9872 (-98.0533)\n",
      "FPR=1.28% (+0.3205%), FNR=3.58% (+1.2472%)\n",
      "                    \n",
      "********************\n",
      "Best features=70\n",
      "Score=0.9860847564832385 (+0.0012650221378873727)\n",
      "tp=624, fn=19, fp=3, tn=935\n",
      "sensitivity=0.9705 (-96.6967), specificity=0.9968 (-98.0437)\n",
      "FPR=0.32% (-0.6395%), FNR=2.95% (+0.6172%)\n",
      "                    \n",
      "********************\n",
      "Best features=100\n",
      "Score=0.9816571790006325 (-0.003162555344718543)\n",
      "tp=623, fn=20, fp=9, tn=929\n",
      "sensitivity=0.9689 (-96.6983), specificity=0.9904 (-98.0501)\n",
      "FPR=0.96% (+0.0005%), FNR=3.11% (+0.7772%)\n",
      "                    \n",
      "********************\n",
      "Best features=150\n",
      "Score=0.9816571790006325 (-0.003162555344718543)\n",
      "tp=622, fn=21, fp=8, tn=930\n",
      "sensitivity=0.9673 (-96.6999), specificity=0.9915 (-98.049)\n",
      "FPR=0.85% (-0.1095%), FNR=3.27% (+0.9372%)\n",
      "                    \n",
      "********************\n",
      "Best features=200\n",
      "Score=0.9810246679316889 (-0.003795066413662229)\n",
      "tp=626, fn=17, fp=13, tn=925\n",
      "sensitivity=0.9736 (-96.6936), specificity=0.9861 (-98.0544)\n",
      "FPR=1.39% (+0.4305%), FNR=2.64% (+0.3072%)\n",
      "                    \n",
      "********************\n",
      "Best features=300\n",
      "Score=0.978494623655914 (-0.006325110689437086)\n",
      "tp=625, fn=18, fp=16, tn=922\n",
      "sensitivity=0.972 (-96.6952), specificity=0.9829 (-98.0576)\n",
      "FPR=1.71% (+0.7505%), FNR=2.8% (+0.4672%)\n",
      "                    \n",
      "********************\n",
      "Best features=400\n",
      "Score=0.9791271347248577 (-0.005692599620493399)\n",
      "tp=619, fn=24, fp=9, tn=929\n",
      "sensitivity=0.9627 (-96.7045), specificity=0.9904 (-98.0501)\n",
      "FPR=0.96% (+0.0005%), FNR=3.73% (+1.3972%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for bestFeatures in bestFeaturesList:\n",
    "    print('*'*20)\n",
    "    print(f'Best features={bestFeatures}')\n",
    "    selector = SelectKBest(chi2, k=bestFeatures)\n",
    "    X_train_skb = selector.fit_transform(X_train, y_train) # fit only on train set!\n",
    "    X_test_skb = selector.transform(X_test)\n",
    "\n",
    "    # standarization\n",
    "    scaler = StandardScaler().fit(X_train_skb) # fit only on train set!\n",
    "    X_train_skb_std = scaler.transform(X_train_skb)\n",
    "    X_test_skb_std = scaler.transform(X_test_skb)\n",
    "\n",
    "    # mlp classifier\n",
    "    mlp_skb = MLPClassifier(random_state=1, max_iter=300, solver='adam')\n",
    "    mlp_skb.fit(X_train_skb_std, y_train)\n",
    "    y_prediction_mlp_skb = mlp_skb.predict(X_test_skb_std)\n",
    "    mlp_skb_score = mlp_skb.score(X_test_skb_std, y_test)\n",
    "\n",
    "    # compare score with default\n",
    "    mlp_skb_diff = mlp_skb_score - mlp_score\n",
    "    print(f'Score={mlp_skb_score} ({mlp_skb_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_skb).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_skb = round(tp/(tp+fn), 4)\n",
    "    specificity_mlp_skb = round(tn/(fp+tn), 4)\n",
    "    \n",
    "    # compare with default\n",
    "    sensitivity_mlp_diff = round(sensitivity_mlp_skb-sensitivity_mlp, 4)\n",
    "    specificity_mlp_diff = round(specificity_mlp_skb-specificity_mlp, 4)\n",
    "    print(\"sensitivity={} ({:+}), specificity={} ({:+})\".format(sensitivity_mlp_skb, sensitivity_mlp_diff, specificity_mlp_skb, specificity_mlp_diff))\n",
    "\n",
    "    # fpr and fnr\n",
    "    fpr_mlp_skb = round((1-specificity_mlp_skb)*100, 4)\n",
    "    fnr_mlp_skb = round((1-sensitivity_mlp_skb)*100, 4)\n",
    "    fpr_mlp_skb_diff = round(fpr_mlp_skb - fpr_mlp, 4)\n",
    "    fnr_mlp_skb_diff = round(fnr_mlp_skb - fnr_mlp, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_skb, fpr_mlp_skb_diff, fnr_mlp_skb, fnr_mlp_skb_diff))\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results for selecting 70 features. FPR has been reduced to 0.32% (less than 0.5%), at the same time FNR was increased by 0.6172% making it to 2.95%. We accept more spam (sensitivity is lower = 97.05%) but we take more valid mails (specificity = 99.68%).\n",
    "\n",
    "* Best features=70\n",
    "* Score=0.9860847564832385 (+0.0013)\n",
    "* tp=624, fn=19, fp=3, tn=935\n",
    "* sensitivity=0.9705 (-0.0062), specificity=0.9968 (+0.0064)\n",
    "* FPR=0.32% (-0.6395%), FNR=2.95% (+0.6172%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest with DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest with DecisionTree\n",
      "********************\n",
      "Best features=50\n",
      "Score=0.9715370018975332 (-0.003162555344718543)\n",
      "tp=607, fn=36, fp=9, tn=929\n",
      "sensitivity=94.4012% (-2.3329%), specificity=99.0405% (+1.0661%)\n",
      "FPR=0.9595% (-1.0661%), FNR=5.5988% (+2.3329%)\n",
      "                    \n",
      "********************\n",
      "Best features=70\n",
      "Score=0.9759645793801391 (+0.0012650221378873727)\n",
      "tp=609, fn=34, fp=4, tn=934\n",
      "sensitivity=94.7123% (-2.0218%), specificity=99.5736% (+1.5992%)\n",
      "FPR=0.4264% (-1.5992%), FNR=5.2877% (+2.0218%)\n",
      "                    \n",
      "********************\n",
      "Best features=100\n",
      "Score=0.9728020240354206 (-0.00189753320683117)\n",
      "tp=607, fn=36, fp=7, tn=931\n",
      "sensitivity=94.4012% (-2.3329%), specificity=99.2537% (+1.2793%)\n",
      "FPR=0.7463% (-1.2793%), FNR=5.5988% (+2.3329%)\n",
      "                    \n",
      "********************\n",
      "Best features=150\n",
      "Score=0.9715370018975332 (-0.003162555344718543)\n",
      "tp=610, fn=33, fp=12, tn=926\n",
      "sensitivity=94.8678% (-1.8663%), specificity=98.7207% (+0.7463%)\n",
      "FPR=1.2793% (-0.7463%), FNR=5.1322% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Best features=200\n",
      "Score=0.9715370018975332 (-0.003162555344718543)\n",
      "tp=621, fn=22, fp=23, tn=915\n",
      "sensitivity=96.5785% (-0.1556%), specificity=97.548% (-0.4264%)\n",
      "FPR=2.452% (+0.4264%), FNR=3.4215% (+0.1556%)\n",
      "                    \n",
      "********************\n",
      "Best features=300\n",
      "Score=0.9740670461733081 (-0.0006325110689436864)\n",
      "tp=618, fn=25, fp=16, tn=922\n",
      "sensitivity=96.112% (-0.6221%), specificity=98.2942% (+0.3198%)\n",
      "FPR=1.7058% (-0.3198%), FNR=3.888% (+0.6221%)\n",
      "                    \n",
      "********************\n",
      "Best features=400\n",
      "Score=0.9765970904490828 (+0.001897533206831059)\n",
      "tp=619, fn=24, fp=13, tn=925\n",
      "sensitivity=96.2675% (-0.4666%), specificity=98.6141% (+0.6397%)\n",
      "FPR=1.3859% (-0.6397%), FNR=3.7325% (+0.4666%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "print('SelectKBest with DecisionTree')\n",
    "for bestFeatures in bestFeaturesList:\n",
    "    print('*'*20)\n",
    "    print(f'Best features={bestFeatures}')\n",
    "    selector = SelectKBest(chi2, k=bestFeatures)\n",
    "    X_train_skb = selector.fit_transform(X_train, y_train) # fit only on train set!\n",
    "    X_test_skb = selector.transform(X_test)\n",
    "\n",
    "    # standarization\n",
    "    scaler = StandardScaler().fit(X_train_skb) # fit only on train set!\n",
    "    X_train_skb_std = scaler.transform(X_train_skb)\n",
    "    X_test_skb_std = scaler.transform(X_test_skb)\n",
    "\n",
    "    # decision tree classifier\n",
    "    dt_skb = DecisionTreeClassifier()\n",
    "    dt_skb.fit(X_train_skb_std, y_train)\n",
    "    y_prediction_dt_skb = dt_skb.predict(X_test_skb_std)\n",
    "    dt_skb_score = dt_skb.score(X_test_skb_std, y_test)\n",
    "\n",
    "    # compare score with default\n",
    "    dt_skb_diff = dt_skb_score - decision_tree_score\n",
    "    print(f'Score={dt_skb_score} ({dt_skb_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_dt_skb).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_dt_skb = round(100*tp/(tp+fn), 4)\n",
    "    specificity_dt_skb = round(100*tn/(fp+tn), 4)\n",
    "    \n",
    "    # compare with default\n",
    "    sensitivity_dt_diff = round(sensitivity_dt_skb-sensitivity_dt, 4)\n",
    "    specificity_dt_diff = round(specificity_dt_skb-specificity_dt, 4)\n",
    "    print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_skb, sensitivity_dt_diff, specificity_dt_skb, specificity_dt_diff))\n",
    "\n",
    "    # fpr and fnr\n",
    "    fpr_dt_skb = round(100-specificity_dt_skb, 4)\n",
    "    fnr_dt_skb = round(100-sensitivity_dt_skb, 4)\n",
    "    fpr_dt_skb_diff = round(fpr_dt_skb - fpr_dt, 4)\n",
    "    fnr_dt_skb_diff = round(fnr_dt_skb - fnr_dt, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_skb, fpr_dt_skb_diff, fnr_dt_skb, fnr_dt_skb_diff))\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA).\n",
    "\n",
    "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "componentsList = [50, 70, 100, 150, 200, 300, 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA with MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Components=50\n",
      "Score=0.9835547122074636 (-0.0012650221378874837)\n",
      "tp=623, fn=20, fp=6, tn=932\n",
      "sensitivity=0.9689 (-96.6983), specificity=0.9936 (-98.0469)\n",
      "FPR=0.64% (-0.3195%), FNR=3.11% (+0.7772%)\n",
      "                    \n",
      "********************\n",
      "Components=70\n",
      "Score=0.9810246679316889 (-0.003795066413662229)\n",
      "tp=619, fn=24, fp=6, tn=932\n",
      "sensitivity=0.9627 (-96.7045), specificity=0.9936 (-98.0469)\n",
      "FPR=0.64% (-0.3195%), FNR=3.73% (+1.3972%)\n",
      "                    \n",
      "********************\n",
      "Components=100\n",
      "Score=0.9803921568627451 (-0.004427577482606027)\n",
      "tp=620, fn=23, fp=8, tn=930\n",
      "sensitivity=0.9642 (-96.703), specificity=0.9915 (-98.049)\n",
      "FPR=0.85% (-0.1095%), FNR=3.58% (+1.2472%)\n",
      "                    \n",
      "********************\n",
      "Components=150\n",
      "Score=0.9778621125869703 (-0.006957621758380772)\n",
      "tp=618, fn=25, fp=10, tn=928\n",
      "sensitivity=0.9611 (-96.7061), specificity=0.9893 (-98.0512)\n",
      "FPR=1.07% (+0.1105%), FNR=3.89% (+1.5572%)\n",
      "                    \n",
      "********************\n",
      "Components=200\n",
      "Score=0.9822896900695762 (-0.0025300442757748565)\n",
      "tp=623, fn=20, fp=8, tn=930\n",
      "sensitivity=0.9689 (-96.6983), specificity=0.9915 (-98.049)\n",
      "FPR=0.85% (-0.1095%), FNR=3.11% (+0.7772%)\n",
      "                    \n",
      "********************\n",
      "Components=300\n",
      "Score=0.9702719797596457 (-0.014547754585705341)\n",
      "tp=605, fn=38, fp=9, tn=929\n",
      "sensitivity=0.9409 (-96.7263), specificity=0.9904 (-98.0501)\n",
      "FPR=0.96% (+0.0005%), FNR=5.91% (+3.5772%)\n",
      "                    \n",
      "********************\n",
      "Components=400\n",
      "Score=0.9753320683111955 (-0.009487666034155628)\n",
      "tp=614, fn=29, fp=10, tn=928\n",
      "sensitivity=0.9549 (-96.7123), specificity=0.9893 (-98.0512)\n",
      "FPR=1.07% (+0.1105%), FNR=4.51% (+2.1772%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for components in componentsList:\n",
    "    print('*'*20)\n",
    "    print(f'Components={components}')\n",
    "    pca = PCA(n_components=components).fit(X_train) # fit only on train set\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # standarize\n",
    "    scaler = StandardScaler().fit(X_train_pca)\n",
    "    X_train_pca_std = scaler.transform(X_train_pca)\n",
    "    X_test_pca_std = scaler.transform(X_test_pca)\n",
    "\n",
    "    # mlp\n",
    "    mlp_pca = MLPClassifier(random_state=1, max_iter=300, solver='adam')\n",
    "    mlp_pca.fit(X_train_pca_std, y_train)\n",
    "    y_prediction_mlp_pca = mlp_pca.predict(X_test_pca_std)\n",
    "    mlp_pca_score = mlp_pca.score(X_test_pca_std, y_test)\n",
    "    \n",
    "    # compare with default\n",
    "    mlp_pca_score_diff = mlp_pca_score - mlp_score\n",
    "    print(f'Score={mlp_pca_score} ({mlp_pca_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_pca).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_pca = round(tp/(tp+fn), 4)\n",
    "    specificity_mlp_pca = round(tn/(fp+tn), 4)\n",
    "    sensitivity_mlp_diff = round(sensitivity_mlp_pca - sensitivity_mlp, 4)\n",
    "    specificity_mlp_diff = round(specificity_mlp_pca - specificity_mlp, 4)\n",
    "    print(\"sensitivity={} ({:+}), specificity={} ({:+})\".format(sensitivity_mlp_pca, sensitivity_mlp_diff, specificity_mlp_pca, specificity_mlp_diff))\n",
    "\n",
    "    # fpr and fnr\n",
    "    fpr_mlp_pca = round((1-specificity_mlp_pca)*100, 4)\n",
    "    fnr_mlp_pca = round((1-sensitivity_mlp_pca)*100, 4)\n",
    "    fpr_mlp_diff = round(fpr_mlp_pca - fpr_mlp, 4)\n",
    "    fnr_mlp_diff = round(fnr_mlp_pca - fnr_mlp, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_pca, fpr_mlp_diff, fnr_mlp_pca, fnr_mlp_diff))\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA with Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Components=50\n",
      "Score=0.9709044908285895 (-0.003795066413662229)\n",
      "tp=620, fn=23, fp=23, tn=915\n",
      "sensitivity=96.423% (-0.3111%), specificity=97.548% (-0.4264%)\n",
      "FPR=2.452% (+0.4264%), FNR=3.577% (+0.3111%)\n",
      "                    \n",
      "********************\n",
      "Components=70\n",
      "Score=0.9601518026565465 (-0.01454775458570523)\n",
      "tp=612, fn=31, fp=32, tn=906\n",
      "sensitivity=95.1788% (-1.5553%), specificity=96.5885% (-1.3859%)\n",
      "FPR=3.4115% (+1.3859%), FNR=4.8212% (+1.5553%)\n",
      "                    \n",
      "********************\n",
      "Components=100\n",
      "Score=0.9658444022770398 (-0.008855154965211942)\n",
      "tp=607, fn=36, fp=18, tn=920\n",
      "sensitivity=94.4012% (-2.3329%), specificity=98.081% (+0.1066%)\n",
      "FPR=1.919% (-0.1066%), FNR=5.5988% (+2.3329%)\n",
      "                    \n",
      "********************\n",
      "Components=150\n",
      "Score=0.9671094244149273 (-0.007590132827324458)\n",
      "tp=610, fn=33, fp=19, tn=919\n",
      "sensitivity=94.8678% (-1.8663%), specificity=97.9744% (+0.0%)\n",
      "FPR=2.0256% (+0.0%), FNR=5.1322% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Components=200\n",
      "Score=0.9652118912080961 (-0.009487666034155628)\n",
      "tp=616, fn=27, fp=28, tn=910\n",
      "sensitivity=95.8009% (-0.9332%), specificity=97.0149% (-0.9595%)\n",
      "FPR=2.9851% (+0.9595%), FNR=4.1991% (+0.9332%)\n",
      "                    \n",
      "********************\n",
      "Components=300\n",
      "Score=0.9671094244149273 (-0.007590132827324458)\n",
      "tp=611, fn=32, fp=20, tn=918\n",
      "sensitivity=95.0233% (-1.7108%), specificity=97.8678% (-0.1066%)\n",
      "FPR=2.1322% (+0.1066%), FNR=4.9767% (+1.7108%)\n",
      "                    \n",
      "********************\n",
      "Components=400\n",
      "Score=0.963314358001265 (-0.011385199240986799)\n",
      "tp=607, fn=36, fp=22, tn=916\n",
      "sensitivity=94.4012% (-2.3329%), specificity=97.6546% (-0.3198%)\n",
      "FPR=2.3454% (+0.3198%), FNR=5.5988% (+2.3329%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for components in componentsList:\n",
    "    print('*'*20)\n",
    "    print(f'Components={components}')\n",
    "    pca = PCA(n_components=components).fit(X_train) # fit only on train set\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # standarize\n",
    "    scaler = StandardScaler().fit(X_train_pca)\n",
    "    X_train_pca_std = scaler.transform(X_train_pca)\n",
    "    X_test_pca_std = scaler.transform(X_test_pca)\n",
    "\n",
    "    # decision tree classifier\n",
    "    dt_pca = DecisionTreeClassifier()\n",
    "    dt_pca.fit(X_train_pca_std, y_train)\n",
    "    y_prediction_dt_pca = dt_pca.predict(X_test_pca_std)\n",
    "    dt_pca_score = dt_pca.score(X_test_pca_std, y_test)\n",
    "    \n",
    "    # compare with default\n",
    "    dt_pca_score_diff = dt_pca_score - decision_tree_score\n",
    "    print(f'Score={dt_pca_score} ({dt_pca_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_dt_pca).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_dt_pca = round(100*tp/(tp+fn), 4)\n",
    "    specificity_dt_pca = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_dt_diff = round(sensitivity_dt_pca - sensitivity_dt, 4)\n",
    "    specificity_dt_diff = round(specificity_dt_pca - specificity_dt, 4)\n",
    "    print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_pca, sensitivity_dt_diff, specificity_dt_pca, specificity_dt_diff))\n",
    "\n",
    "    # fpr and fnr\n",
    "    fpr_dt_pca = round(100-specificity_dt_pca, 4)\n",
    "    fnr_dt_pca = round(100-sensitivity_dt_pca, 4)\n",
    "    fpr_dt_diff = round(fpr_dt_pca - fpr_dt, 4)\n",
    "    fnr_dt_diff = round(fnr_dt_pca - fnr_dt, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_pca, fpr_dt_diff, fnr_dt_pca, fnr_dt_diff))\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methods for class-imbalanced problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to perform over-sampling using SMOTE - Synthetic Minority over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train dataset shape: Counter({'no': 2011, 'yes': 1197})\n"
     ]
    }
   ],
   "source": [
    "print(f'Original train dataset shape: {Counter(y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that originally train set contains more non spam data. SMOTE algorithm will add spam samples to train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled train dataset shape: Counter({'yes': 2011, 'no': 2011})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "print(f'Resampled train dataset shape: {Counter(y_train_res)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how it affects sensitivity and specificity on MLP and DecisionTree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarization\n",
    "scaler = StandardScaler().fit(X_train_res, y_train_res)\n",
    "X_train_res_std = scaler.transform(X_train_res)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9740670461733081 (-0.010752688172043001)\n",
      "tp=621, fn=22, fp=19, tn=919\n",
      "sensitivity=96.5785% (-1.0887%), specificity=97.9744% (-1.0661%)\n",
      "FPR=2.0256% (+1.0661%), FNR=3.4215% (+1.0887%)\n"
     ]
    }
   ],
   "source": [
    "# mlp classifier\n",
    "mlp_smote = MLPClassifier(random_state=1, max_iter=300, solver='adam')\n",
    "mlp_smote.fit(X_train_res_std, y_train_res)\n",
    "y_prediction_mlp_smote = mlp_smote.predict(X_test_std)\n",
    "mlp_smote_score = mlp_smote.score(X_test_std, y_test)\n",
    "mlp_score_diff = mlp_smote_score - mlp_score\n",
    "print(f'Score={mlp_smote_score} ({mlp_score_diff:+})')\n",
    "\n",
    "# confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_smote).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "\n",
    "sensitivity_mlp_smote = round(100*tp/(tp+fn), 4)\n",
    "specificity_mlp_smote = round(100*tn/(fp+tn), 4)\n",
    "sensitivity_mlp_diff = round(sensitivity_mlp_smote - sensitivity_mlp, 4)\n",
    "specificity_mlp_diff = round(specificity_mlp_smote - specificity_mlp, 4)\n",
    "\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_mlp_smote, sensitivity_mlp_diff, specificity_mlp_smote, specificity_mlp_diff))\n",
    "\n",
    "fpr_mlp_smote = round(100-specificity_mlp_smote, 4)\n",
    "fnr_mlp_smote = round(100-sensitivity_mlp_smote, 4)\n",
    "fpr_mlp_diff = round(fpr_mlp_smote - fpr_mlp, 4)\n",
    "fnr_mlp_diff = round(fnr_mlp_smote - fnr_mlp, 4)\n",
    "print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_smote, fpr_mlp_diff, fnr_mlp_smote, fnr_mlp_diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.958886780518659 (-0.015812776723592714)\n",
      "tp=608, fn=35, fp=30, tn=908\n",
      "sensitivity=94.5568% (-2.1773%), specificity=96.8017% (-1.1727%)\n",
      "FPR=3.1983% (+1.1727%), FNR=5.4432% (+2.1773%)\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "dt_smote = DecisionTreeClassifier()\n",
    "dt_smote.fit(X_train_res_std, y_train_res)\n",
    "y_prediction_dt_smote = dt_smote.predict(X_test_std)\n",
    "dt_smote_score = dt_smote.score(X_test_std, y_test)\n",
    "dt_score_diff = dt_smote_score - decision_tree_score\n",
    "print(f'Score={dt_smote_score} ({dt_score_diff:+})')\n",
    "\n",
    "# confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_dt_smote).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "\n",
    "sensitivity_dt_smote = round(100*tp/(tp+fn), 4)\n",
    "specificity_dt_smote = round(100*tn/(fp+tn), 4)\n",
    "sensitivity_dt_diff = round(sensitivity_dt_smote - sensitivity_dt, 4)\n",
    "specificity_dt_diff = round(specificity_dt_smote - specificity_dt, 4)\n",
    "\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_smote, sensitivity_dt_diff, specificity_dt_smote, specificity_dt_diff))\n",
    "\n",
    "fpr_dt_smote = round(100-specificity_dt_smote, 4)\n",
    "fnr_dt_smote = round(100-sensitivity_dt_smote, 4)\n",
    "fpr_dt_diff = round(fpr_dt_smote - fpr_dt, 4)\n",
    "fnr_dt_diff = round(fnr_dt_smote - fnr_dt, 4)\n",
    "print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_smote, fpr_dt_diff, fnr_dt_smote, fnr_dt_diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Misclassification costs - aware learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ensamble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "MLPClassifier doesn't support sample_weight.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14740/69619034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ada boost classifier with base estimator mlp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0madaClf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madaClf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_standarized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_pred_adaClf1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0madaClf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_standarized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0madaClf1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madaClf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_standarized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m# Check parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Clear any previous fit results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_validate_estimator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    501\u001b[0m                 )\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_fit_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sample_weight\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    504\u001b[0m                 \u001b[1;34m\"%s doesn't support sample_weight.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: MLPClassifier doesn't support sample_weight."
     ]
    }
   ],
   "source": [
    "# ada boost classifier with base estimator mlp\n",
    "adaClf1 = AdaBoostClassifier(base_estimator=mlp, n_estimators=100, learning_rate=1, random_state=1)\n",
    "\n",
    "# ERROR: MLPClassifier doesn't support sample_weight.\n",
    "# adaClf1.fit(X_train_standarized, y_train)\n",
    "# y_pred_adaClf1= adaClf1.predict(X_test_standarized)\n",
    "# adaClf1_score = adaClf1.score(X_test_standarized, y_test)\n",
    "# mlp_diff = adaClf1_score - mlp_score\n",
    "# print(f'AdaBoostClassifier score={adaClf1_score} ({mlp_diff:+})')\n",
    "\n",
    "# # confusion matrix\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_pred_adaClf1).ravel()\n",
    "# print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "# sensitivity_adaClf1 = round(100*tp/(tp+fn), 4)\n",
    "# specificity_adaClf1 = round(100*tn/(fp+tn), 4)\n",
    "# sensitivity_mlp_diff = round(sensitivity_adaClf1 - sensitivity_mlp, 4)\n",
    "# specificity_mlp_diff = round(specificity_adaClf1 - specificity_mlp)\n",
    "# print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_adaClf1, sensitivity_mlp_diff, specificity_adaClf1, specificity_mlp_diff))\n",
    "\n",
    "# fpr_adaClf1 = round(100-specificity_adaClf1, 4)\n",
    "# fnr_adaClf1 = round(100-sensitivity_adaClf1, 4)\n",
    "# fpr_mlp_diff = round(fpr_adaClf1 - fpr_mlp, 4)\n",
    "# fnr_mlp_diff = round(fnr_adaClf1 - fnr_mlp, 4)\n",
    "# print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_adaClf1, fpr_mlp_diff, fnr_adaClf1, fnr_mlp_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier score=0.9803921568627451 (+0.005692599620493288)\n",
      "tp=618, fn=25, fp=6, tn=932\n",
      "sensitivity=96.112% (-0.6221%), specificity=99.3603% (+1%)\n",
      "FPR=0.6397% (-1.3859%), FNR=3.888% (+0.6221%)\n"
     ]
    }
   ],
   "source": [
    "# ada boost classifier with base estimator decisionTree\n",
    "adaClf2 = AdaBoostClassifier(base_estimator=decisionTree, n_estimators=100, learning_rate=1, random_state=1)\n",
    "adaClf2.fit(X_train_standarized, y_train)\n",
    "y_pred_adaClf2= adaClf2.predict(X_test_standarized)\n",
    "adaClf2_score = adaClf2.score(X_test_standarized, y_test)\n",
    "dt_diff = adaClf2_score - decision_tree_score\n",
    "print(f'AdaBoostClassifier score={adaClf2_score} ({dt_diff:+})')\n",
    "\n",
    "# confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_adaClf2).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_adaClf2 = round(100*tp/(tp+fn), 4)\n",
    "specificity_adaClf2 = round(100*tn/(fp+tn), 4)\n",
    "sensitivity_dt_diff = round(sensitivity_adaClf2 - sensitivity_dt, 4)\n",
    "specificity_dt_diff = round(specificity_adaClf2 - specificity_dt)\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_adaClf2, sensitivity_dt_diff, specificity_adaClf2, specificity_dt_diff))\n",
    "\n",
    "fpr_adaClf2 = round(100-specificity_adaClf2, 4)\n",
    "fnr_adaClf2 = round(100-sensitivity_adaClf2, 4)\n",
    "fpr_dt_diff = round(fpr_adaClf2 - fpr_dt, 4)\n",
    "fnr_dt_diff = round(fnr_adaClf2 - fnr_dt, 4)\n",
    "print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_adaClf2, fpr_dt_diff, fnr_adaClf2, fnr_dt_diff))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "160a8e799b4c8ac5e6b5e507c10561fe57290204298c2a882096e26ea13919e6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

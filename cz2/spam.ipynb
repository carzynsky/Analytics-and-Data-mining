{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classifier algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE, SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arek\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --user matplotlib\n",
    "dataFrame = pd.read_csv('./data/spam.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4789, 463)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4789 entries, 0 to 4788\n",
      "Columns: 463 entries, ACT_NOW to target\n",
      "dtypes: int64(462), object(1)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dataFrame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT_NOW</th>\n",
       "      <th>ADDRESSES_ON_CD</th>\n",
       "      <th>ADULT_SITE</th>\n",
       "      <th>ADVERT_CODE</th>\n",
       "      <th>ADVERT_CODE2</th>\n",
       "      <th>ALL_CAPS_HEADER</th>\n",
       "      <th>ALL_CAP_PORN</th>\n",
       "      <th>ALL_NATURAL</th>\n",
       "      <th>AMATEUR_PORN</th>\n",
       "      <th>AMAZING</th>\n",
       "      <th>...</th>\n",
       "      <th>X_AUTH_WARNING</th>\n",
       "      <th>X_ENC_PRESENT</th>\n",
       "      <th>X_LIBRARY</th>\n",
       "      <th>X_LIST_UNSUBSCRIBE</th>\n",
       "      <th>X_MSMAIL_PRIORITY_HIGH</th>\n",
       "      <th>X_PRECEDENCE_REF</th>\n",
       "      <th>X_PRIORITY_HIGH</th>\n",
       "      <th>X_STORMPOST_TO</th>\n",
       "      <th>X_X_PRESENT</th>\n",
       "      <th>YOUR_INCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315097</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.089883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.074882</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.043315</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464603</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.113055</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.020434</td>\n",
       "      <td>0.138009</td>\n",
       "      <td>0.028892</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.025023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ACT_NOW  ADDRESSES_ON_CD   ADULT_SITE  ADVERT_CODE  ADVERT_CODE2  \\\n",
       "count  4789.000000           4789.0  4789.000000  4789.000000   4789.000000   \n",
       "mean      0.008144              0.0     0.006056     0.000209      0.006682   \n",
       "std       0.089883              0.0     0.077590     0.014450      0.081478   \n",
       "min       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "25%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "50%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "75%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "max       1.000000              0.0     1.000000     1.000000      1.000000   \n",
       "\n",
       "       ALL_CAPS_HEADER  ALL_CAP_PORN  ALL_NATURAL  AMATEUR_PORN      AMAZING  \\\n",
       "count      4789.000000   4789.000000  4789.000000   4789.000000  4789.000000   \n",
       "mean          0.000626      0.005638     0.007308      0.001879     0.002088   \n",
       "std           0.025023      0.074882     0.085185      0.043315     0.045653   \n",
       "min           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "25%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "50%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "75%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "max           1.000000      1.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       ...  X_AUTH_WARNING  X_ENC_PRESENT    X_LIBRARY  X_LIST_UNSUBSCRIBE  \\\n",
       "count  ...     4789.000000    4789.000000  4789.000000         4789.000000   \n",
       "mean   ...        0.315097       0.001044     0.000626            0.012946   \n",
       "std    ...        0.464603       0.032298     0.025023            0.113055   \n",
       "min    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "25%    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "50%    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "75%    ...        1.000000       0.000000     0.000000            0.000000   \n",
       "max    ...        1.000000       1.000000     1.000000            1.000000   \n",
       "\n",
       "       X_MSMAIL_PRIORITY_HIGH  X_PRECEDENCE_REF  X_PRIORITY_HIGH  \\\n",
       "count             4789.000000       4789.000000      4789.000000   \n",
       "mean                 0.009397          0.000418         0.019420   \n",
       "std                  0.096489          0.020434         0.138009   \n",
       "min                  0.000000          0.000000         0.000000   \n",
       "25%                  0.000000          0.000000         0.000000   \n",
       "50%                  0.000000          0.000000         0.000000   \n",
       "75%                  0.000000          0.000000         0.000000   \n",
       "max                  1.000000          1.000000         1.000000   \n",
       "\n",
       "       X_STORMPOST_TO  X_X_PRESENT  YOUR_INCOME  \n",
       "count     4789.000000  4789.000000  4789.000000  \n",
       "mean         0.000835     0.001253     0.000626  \n",
       "std          0.028892     0.035377     0.025023  \n",
       "min          0.000000     0.000000     0.000000  \n",
       "25%          0.000000     0.000000     0.000000  \n",
       "50%          0.000000     0.000000     0.000000  \n",
       "75%          0.000000     0.000000     0.000000  \n",
       "max          1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 462 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is data balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     2949\n",
       "yes    1840\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows=3208, test rows: 1581\n"
     ]
    }
   ],
   "source": [
    "X = dataFrame.drop(['target'], axis=1)\n",
    "y = dataFrame.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=331, test_size=0.33)\n",
    "print(f'Train rows={X_train.shape[0]}, test rows: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_standarized = scaler.transform(X_train) \n",
    "X_test_standarized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9753320683111955\n"
     ]
    }
   ],
   "source": [
    "svm = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "svm.fit(X_train_standarized, y_train)\n",
    "y_prediction_svm = svm.predict(X_test_standarized)\n",
    "svm_score = svm.score(X_test_standarized, y_test)\n",
    "print(f'Score={svm_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=616, fn=27, fp=12, tn=926\n",
      "sensitivity=0.9580, specificity=0.9872\n",
      "FPR=1.2793%, FNR=4.1991%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_svm).ravel()\n",
    "plot_confusion_matrix(svm, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9272612270714737\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_standarized, y_train)\n",
    "y_prediction_knn = knn.predict(X_test_standarized)\n",
    "knn_score = knn.score(X_test_standarized, y_test)\n",
    "print(f'Score={knn_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=537, fn=106, fp=9, tn=929\n",
      "sensitivity=0.8351, specificity=0.9904\n",
      "FPR=0.9595%, FNR=16.4852%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_knn).ravel()\n",
    "plot_confusion_matrix(knn, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9728020240354206\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_prediction_gnb = gnb.predict(X_test)\n",
    "gnb_score = gnb.score(X_test, y_test)\n",
    "print(f'Score={gnb_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=609, fn=34, fp=9, tn=929\n",
      "sensitivity=0.9471, specificity=0.9904\n",
      "FPR=0.9595%, FNR=5.2877%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_gnb).ravel()\n",
    "plot_confusion_matrix(gnb, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9848197343453511\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=1, max_iter=300, solver='adam')\n",
    "mlp.fit(X_train_standarized, y_train)\n",
    "y_prediction_mlp = mlp.predict(X_test_standarized)\n",
    "mlp_score = mlp.score(X_test_standarized, y_test)\n",
    "print(f'Score={mlp_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=628, fn=15, fp=9, tn=929\n",
      "sensitivity=97.6672%, specificity=99.0405%\n",
      "FPR=0.9595%, FNR=2.3328%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp).ravel()\n",
    "plot_confusion_matrix(mlp, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_mlp = round(100*tp/(tp+fn), 4)\n",
    "specificity_mlp = round(100*tn/(fp+tn), 4)\n",
    "print(\"sensitivity={}%, specificity={}%\".format(sensitivity_mlp, specificity_mlp))\n",
    "\n",
    "fpr_mlp = round(100-specificity_mlp, 4)\n",
    "fnr_mlp = round(100-sensitivity_mlp, 4)\n",
    "print(\"FPR={}%, FNR={}%\".format(fpr_mlp, fnr_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9772296015180265\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier()\n",
    "decisionTree.fit(X_train_standarized, y_train)\n",
    "y_prediction_decision_tree = decisionTree.predict(X_test_standarized)\n",
    "decision_tree_score = decisionTree.score(X_test_standarized, y_test)\n",
    "print(f'Score={decision_tree_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=623, fn=20, fp=16, tn=922\n",
      "sensitivity=96.8896%, specificity=98.2942%\n",
      "FPR=1.7058%, FNR=3.1104%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_decision_tree).ravel()\n",
    "plot_confusion_matrix(decisionTree, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_dt = round(100*tp/(tp+fn), 4)\n",
    "specificity_dt = round(100*tn/(fp+tn), 4)\n",
    "print(\"sensitivity={:.4f}%, specificity={:.4f}%\".format(sensitivity_dt, specificity_dt))\n",
    "\n",
    "fpr_dt = round(100-specificity_dt, 4)\n",
    "fnr_dt = round(100-sensitivity_dt, 4)\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr_dt, fnr_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9639468690702088\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "rfc.fit(X_train_standarized, y_train)\n",
    "y_prediction_rfc = rfc.predict(X_test_standarized)\n",
    "rfc_score = rfc.score(X_test_standarized, y_test)\n",
    "print(f'Score={rfc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=591, fn=52, fp=5, tn=933\n",
      "sensitivity=0.9191, specificity=0.9947\n",
      "FPR=0.5330%, FNR=8.0871%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_rfc).ravel()\n",
    "plot_confusion_matrix(rfc, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9765970904490828\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train_standarized, y_train)\n",
    "y_prediction_lr = lr.predict(X_test_standarized)\n",
    "lr_score = lr.score(X_test_standarized, y_test)\n",
    "print(f'Score={lr_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arek\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=616, fn=27, fp=10, tn=928\n",
      "sensitivity=0.9580, specificity=0.9893\n",
      "FPR=1.0661%, FNR=4.1991%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_lr).ravel()\n",
    "plot_confusion_matrix(lr, X_test_standarized, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "print(\"sensitivity={:.4f}, specificity={:.4f}\".format(sensitivity, specificity))\n",
    "\n",
    "fpr = (1-specificity)*100\n",
    "fnr = (1-sensitivity)*100\n",
    "print(\"FPR={:.4f}%, FNR={:.4f}%\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classifier parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default MLP has solver 'adam'. \n",
    "The solver for weight optimization.\n",
    "* ‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n",
    "* ‘sgd’ refers to stochastic gradient descent.\n",
    "* ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "\n",
    "Note: The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.\n",
    "(source: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with lbfgs solver=0.978494623655914 (-0.006325110689437086)\n",
      "tp=625, fn=18, fp=16, tn=922\n",
      "sensitivity=97.2006% (-0.4666%), specificity=98.2942% (-0.7463%)\n",
      "lbfgs solver: FPR=1.7058% (+0.7463%), FNR=2.7994% (+0.4666%)\n"
     ]
    }
   ],
   "source": [
    "# solver lbfgs\n",
    "mlp_lbfgs = MLPClassifier(random_state=1, max_iter=300, solver='lbfgs')\n",
    "mlp_lbfgs.fit(X_train_standarized, y_train)\n",
    "y_prediction_mlp_lbfgs = mlp_lbfgs.predict(X_test_standarized)\n",
    "mlp_lbfgs_score = mlp_lbfgs.score(X_test_standarized, y_test)\n",
    "mlp_score_diff = mlp_lbfgs_score-mlp_score\n",
    "print(f'Score with lbfgs solver={mlp_lbfgs_score} ({mlp_score_diff:+})')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_lbfgs).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_mlp_lbfgs = round(100*tp/(tp+fn), 4)\n",
    "specificity_mlp_lbfgs = round(100*tn/(fp+tn), 4)\n",
    "sensitivity_mlp_diff = round(sensitivity_mlp_lbfgs - sensitivity_mlp, 4)\n",
    "specificity_mlp_diff = round(specificity_mlp_lbfgs - specificity_mlp, 4)\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_mlp_lbfgs, sensitivity_mlp_diff, specificity_mlp_lbfgs, specificity_mlp_diff))\n",
    "\n",
    "fpr_mlp_lbfgs = round(100-specificity_mlp_lbfgs, 4)\n",
    "fnr_mlp_lbfgs = round(100-sensitivity_mlp_lbfgs, 4)\n",
    "fpr_mlp_diff = round(fpr_mlp_lbfgs - fpr_mlp, 4)\n",
    "fnr_mlp_diff = round(fnr_mlp_lbfgs - fnr_mlp, 4)\n",
    "print(\"lbfgs solver: FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_lbfgs, fpr_mlp_diff, fnr_mlp_lbfgs, fnr_mlp_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with sgd solver=0.9791271347248577 (-0.005692599620493399)\n",
      "tp=619, fn=24, fp=9, tn=929\n",
      "sensitivity=96.2675% (-1.3997%), specificity=99.0405% (+0.0%)\n",
      "sgd solver: FPR=0.9595% (+0.0%), FNR=3.7325% (+1.3997%)\n"
     ]
    }
   ],
   "source": [
    "# sgd\n",
    "mlp_sgd = MLPClassifier(random_state=1, max_iter=300, solver='sgd')\n",
    "mlp_sgd.fit(X_train_standarized, y_train)\n",
    "y_prediction_mlp_sgd = mlp_sgd.predict(X_test_standarized)\n",
    "mlp_sgd_score = mlp_sgd.score(X_test_standarized, y_test)\n",
    "mlp_score_diff = mlp_sgd_score-mlp_score\n",
    "print(f'Score with sgd solver={mlp_sgd_score} ({mlp_score_diff:+})')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_sgd).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "sensitivity_mlp_sgd = round(100*tp/(tp+fn), 4)\n",
    "specificity_mlp_sgd= round(100*tn/(fp+tn), 4)\n",
    "sensitivity_mlp_diff = round(sensitivity_mlp_sgd - sensitivity_mlp, 4)\n",
    "specificity_mlp_diff = round(specificity_mlp_sgd - specificity_mlp, 4)\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_mlp_sgd, sensitivity_mlp_diff, specificity_mlp_sgd, specificity_mlp_diff))\n",
    "\n",
    "fpr_mlp_sgd = round(100-specificity_mlp_sgd, 4)\n",
    "fnr_mlp_sgd = round(100-sensitivity_mlp_sgd, 4)\n",
    "fpr_mlp_diff = round(fpr_mlp_sgd - fpr_mlp, 4)\n",
    "fnr_mlp_diff = round(fnr_mlp_sgd - fnr_mlp, 4)\n",
    "print(\"sgd solver: FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_sgd, fpr_mlp_diff, fnr_mlp_sgd, fnr_mlp_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layers and number of neurons\n",
    "By default there is 1 hidden layer with 100 neurons. In hidden_layer_neuron_numbers there are number of neurons in hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Number of neurons in hidden layer = 8\n",
      "Score=0.9778621125869703, score with default=0.9835547122074636 (-0.005692599620493288)\n",
      "tp=616, fn=27, fp=8, tn=930\n",
      "sensitivity=0.9580093312597201 (-0.01710730948678063), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=4.1991% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 16\n",
      "Score=0.9797596457938014, score with default=0.9835547122074636 (-0.003795066413662229)\n",
      "tp=618, fn=25, fp=7, tn=931\n",
      "sensitivity=0.9611197511664075 (-0.013996889580093264), specificity=0.9925373134328358 (+0.0031982942430703876)\n",
      "FPR=0.7463% (-0.3198%), FNR=3.8880% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 32\n",
      "Score=0.9772296015180265, score with default=0.9835547122074636 (-0.006325110689437086)\n",
      "tp=615, fn=28, fp=8, tn=930\n",
      "sensitivity=0.9564541213063764 (-0.018662519440124314), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=4.3546% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 40\n",
      "Score=0.9772296015180265, score with default=0.9835547122074636 (-0.006325110689437086)\n",
      "tp=616, fn=27, fp=9, tn=929\n",
      "sensitivity=0.9580093312597201 (-0.01710730948678063), specificity=0.990405117270789 (+0.0010660980810235365)\n",
      "FPR=0.9595% (-0.1066%), FNR=4.1991% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 50\n",
      "Score=0.9778621125869703, score with default=0.9835547122074636 (-0.005692599620493288)\n",
      "tp=616, fn=27, fp=8, tn=930\n",
      "sensitivity=0.9580093312597201 (-0.01710730948678063), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=4.1991% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 64\n",
      "Score=0.9765970904490828, score with default=0.9835547122074636 (-0.006957621758380772)\n",
      "tp=615, fn=28, fp=9, tn=929\n",
      "sensitivity=0.9564541213063764 (-0.018662519440124314), specificity=0.990405117270789 (+0.0010660980810235365)\n",
      "FPR=0.9595% (-0.1066%), FNR=4.3546% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 100\n",
      "Score=0.978494623655914, score with default=0.9835547122074636 (-0.005060088551549602)\n",
      "tp=617, fn=26, fp=8, tn=930\n",
      "sensitivity=0.9595645412130638 (-0.015552099533436947), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=4.0435% (+1.5552%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 128\n",
      "Score=0.9753320683111955, score with default=0.9835547122074636 (-0.008222643896268145)\n",
      "tp=616, fn=27, fp=12, tn=926\n",
      "sensitivity=0.9580093312597201 (-0.01710730948678063), specificity=0.9872068230277186 (-0.002132196162046851)\n",
      "FPR=1.2793% (+0.2132%), FNR=4.1991% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 256\n",
      "Score=0.9791271347248577, score with default=0.9835547122074636 (-0.0044275774826059155)\n",
      "tp=619, fn=24, fp=9, tn=929\n",
      "sensitivity=0.9626749611197511 (-0.01244167962674958), specificity=0.990405117270789 (+0.0010660980810235365)\n",
      "FPR=0.9595% (-0.1066%), FNR=3.7325% (+1.2442%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "# 1 hidden layer\n",
    "hidden_layer_neuron_numbers = [8, 16, 32, 40, 50, 64, 100, 128, 256]\n",
    "for i in range(len(hidden_layer_neuron_numbers)):\n",
    "    print('*'*20)\n",
    "    print(f'Number of neurons in hidden layer = {hidden_layer_neuron_numbers[i]}')\n",
    "    mlp_hidden_layer_test = MLPClassifier(random_state=1, max_iter=4000, hidden_layer_sizes=(hidden_layer_neuron_numbers[i]), solver='sgd')\n",
    "    mlp_hidden_layer_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_mlp_hidden_layer_test = mlp_hidden_layer_test.predict(X_test_standarized)\n",
    "    mlp_hidden_layer_test_score = mlp_hidden_layer_test.score(X_test_standarized, y_test)\n",
    "    score_sign = '+'\n",
    "    if(mlp_score > mlp_hidden_layer_test_score):\n",
    "        score_sign = '-'\n",
    "    print(f'Score={mlp_hidden_layer_test_score}, score with default={mlp_score} ({score_sign}{abs(mlp_hidden_layer_test_score - mlp_score)})')\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_hidden_layer_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_hidden_layer_test = tp/(tp+fn)\n",
    "    specificity_mlp_hidden_layer_test = tn/(fp+tn)\n",
    "    sensitivity_sign = '+'\n",
    "    if(sensitivity_mlp > sensitivity_mlp_hidden_layer_test):\n",
    "        sensitivity_sign = '-'\n",
    "\n",
    "    specificity_sign = '+'\n",
    "    if(specificity_mlp > specificity_mlp_hidden_layer_test):\n",
    "        specificity_sign = '-'\n",
    "\n",
    "    print(f'sensitivity={sensitivity_mlp_hidden_layer_test} ({sensitivity_sign}{abs(sensitivity_mlp_hidden_layer_test-sensitivity_mlp)}), specificity={specificity_mlp_hidden_layer_test} ({specificity_sign}{abs(specificity_mlp_hidden_layer_test-specificity_mlp)})')\n",
    "    \n",
    "    fpr_mlp_hidden_layer_test = (1-specificity_mlp_hidden_layer_test)*100\n",
    "    fpr_sign = '+'\n",
    "    if(fpr_mlp > fpr_mlp_hidden_layer_test):\n",
    "        fpr_sign = '-'\n",
    "\n",
    "    fnr_mlp_hidden_layer_test  = (1-sensitivity_mlp_hidden_layer_test)*100\n",
    "    fnr_sign='+'\n",
    "    if(fnr_mlp > fnr_mlp_hidden_layer_test):\n",
    "        fnr_sign = '-'\n",
    "\n",
    "    fpr_format = '{:.4f}'.format(fpr_mlp_hidden_layer_test)\n",
    "    fnr_format = '{:.4f}'.format(fnr_mlp_hidden_layer_test)\n",
    "    fpr_diff_format = '{:.4f}'.format(abs(fpr_mlp_hidden_layer_test-fpr_mlp))\n",
    "    fnr_diff_format='{:.4f}'.format(abs(fnr_mlp_hidden_layer_test-fnr_mlp))\n",
    "    print(f'FPR={fpr_format}% ({fpr_sign}{fpr_diff_format}%), FNR={fnr_format}% ({fnr_sign}{fnr_diff_format}%)')\n",
    "    print(' '*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning_rate schedule for weight updates. (By default 'constant', only used when solver is 'sgd')\n",
    "* ‘constant’ is a constant learning rate given by ‘learning_rate_init’.\n",
    "\n",
    "* ‘invscaling’ gradually decreases the learning rate at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "\n",
    "* ‘adaptive’ keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if ‘early_stopping’ is on, the current learning rate is divided by 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Number of neurons in hidden layer = 8\n",
      "Score=0.7330803289057558, score with default=0.9835547122074636 (-0.2504743833017078)\n",
      "tp=242, fn=401, fp=21, tn=917\n",
      "sensitivity=0.37636080870917576 (-0.598755832037325), specificity=0.9776119402985075 (-0.011727078891257903)\n",
      "FPR=2.2388% (+1.1727%), FNR=62.3639% (+59.8756%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 16\n",
      "Score=0.5850727387729285, score with default=0.9835547122074636 (-0.39848197343453506)\n",
      "tp=448, fn=195, fp=461, tn=477\n",
      "sensitivity=0.6967340590979783 (-0.2783825816485225), specificity=0.5085287846481876 (-0.4808102345415778)\n",
      "FPR=49.1471% (+48.0810%), FNR=30.3266% (+27.8383%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 32\n",
      "Score=0.7906388361796332, score with default=0.9835547122074636 (-0.19291587602783045)\n",
      "tp=333, fn=310, fp=21, tn=917\n",
      "sensitivity=0.5178849144634525 (-0.4572317262830482), specificity=0.9776119402985075 (-0.011727078891257903)\n",
      "FPR=2.2388% (+1.1727%), FNR=48.2115% (+45.7232%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 40\n",
      "Score=0.7925363693864642, score with default=0.9835547122074636 (-0.1910183428209994)\n",
      "tp=430, fn=213, fp=115, tn=823\n",
      "sensitivity=0.6687402799377916 (-0.3063763608087091), specificity=0.8773987206823027 (-0.11194029850746268)\n",
      "FPR=12.2601% (+11.1940%), FNR=33.1260% (+30.6376%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 50\n",
      "Score=0.7096774193548387, score with default=0.9835547122074636 (-0.27387729285262485)\n",
      "tp=519, fn=124, fp=335, tn=603\n",
      "sensitivity=0.807153965785381 (-0.16796267496111972), specificity=0.6428571428571429 (-0.3464818763326225)\n",
      "FPR=35.7143% (+34.6482%), FNR=19.2846% (+16.7963%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 64\n",
      "Score=0.7836812144212524, score with default=0.9835547122074636 (-0.19987349778621122)\n",
      "tp=429, fn=214, fp=128, tn=810\n",
      "sensitivity=0.6671850699844479 (-0.3079315707620528), specificity=0.8635394456289979 (-0.12579957356076754)\n",
      "FPR=13.6461% (+12.5800%), FNR=33.2815% (+30.7932%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 100\n",
      "Score=0.8165717900063251, score with default=0.9835547122074636 (-0.16698292220113853)\n",
      "tp=423, fn=220, fp=70, tn=868\n",
      "sensitivity=0.6578538102643857 (-0.317262830482115), specificity=0.9253731343283582 (-0.0639658848614072)\n",
      "FPR=7.4627% (+6.3966%), FNR=34.2146% (+31.7263%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 128\n",
      "Score=0.8475648323845667, score with default=0.9835547122074636 (-0.1359898798228969)\n",
      "tp=533, fn=110, fp=131, tn=807\n",
      "sensitivity=0.8289269051321928 (-0.14618973561430793), specificity=0.8603411513859275 (-0.12899786780383793)\n",
      "FPR=13.9659% (+12.8998%), FNR=17.1073% (+14.6190%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 256\n",
      "Score=0.845034788108792, score with default=0.9835547122074636 (-0.13851992409867164)\n",
      "tp=577, fn=66, fp=179, tn=759\n",
      "sensitivity=0.8973561430793157 (-0.07776049766718507), specificity=0.8091684434968017 (-0.18017057569296369)\n",
      "FPR=19.0832% (+18.0171%), FNR=10.2644% (+7.7760%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "# learning_rate='invscaling'\n",
    "for i in range(len(hidden_layer_neuron_numbers)):\n",
    "    print('*'*20)\n",
    "    print(f'Number of neurons in hidden layer = {hidden_layer_neuron_numbers[i]}')\n",
    "    mlp_hidden_layer_test = MLPClassifier(random_state=1, max_iter=4000, hidden_layer_sizes=(hidden_layer_neuron_numbers[i]), solver='sgd', learning_rate='invscaling')\n",
    "    mlp_hidden_layer_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_mlp_hidden_layer_test = mlp_hidden_layer_test.predict(X_test_standarized)\n",
    "    mlp_hidden_layer_test_score = mlp_hidden_layer_test.score(X_test_standarized, y_test)\n",
    "    score_sign = '+'\n",
    "    if(mlp_score > mlp_hidden_layer_test_score):\n",
    "        score_sign = '-'\n",
    "    print(f'Score={mlp_hidden_layer_test_score}, score with default={mlp_score} ({score_sign}{abs(mlp_hidden_layer_test_score - mlp_score)})')\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_hidden_layer_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_hidden_layer_test = tp/(tp+fn)\n",
    "    specificity_mlp_hidden_layer_test = tn/(fp+tn)\n",
    "    sensitivity_sign = '+'\n",
    "    if(sensitivity_mlp > sensitivity_mlp_hidden_layer_test):\n",
    "        sensitivity_sign = '-'\n",
    "\n",
    "    specificity_sign = '+'\n",
    "    if(specificity_mlp > specificity_mlp_hidden_layer_test):\n",
    "        specificity_sign = '-'\n",
    "\n",
    "    print(f'sensitivity={sensitivity_mlp_hidden_layer_test} ({sensitivity_sign}{abs(sensitivity_mlp_hidden_layer_test-sensitivity_mlp)}), specificity={specificity_mlp_hidden_layer_test} ({specificity_sign}{abs(specificity_mlp_hidden_layer_test-specificity_mlp)})')\n",
    "    \n",
    "    fpr_mlp_hidden_layer_test = (1-specificity_mlp_hidden_layer_test)*100\n",
    "    fpr_sign = '+'\n",
    "    if(fpr_mlp > fpr_mlp_hidden_layer_test):\n",
    "        fpr_sign = '-'\n",
    "\n",
    "    fnr_mlp_hidden_layer_test  = (1-sensitivity_mlp_hidden_layer_test)*100\n",
    "    fnr_sign='+'\n",
    "    if(fnr_mlp > fnr_mlp_hidden_layer_test):\n",
    "        fnr_sign = '-'\n",
    "\n",
    "    fpr_format = '{:.4f}'.format(fpr_mlp_hidden_layer_test)\n",
    "    fnr_format = '{:.4f}'.format(fnr_mlp_hidden_layer_test)\n",
    "    fpr_diff_format = '{:.4f}'.format(abs(fpr_mlp_hidden_layer_test-fpr_mlp))\n",
    "    fnr_diff_format='{:.4f}'.format(abs(fnr_mlp_hidden_layer_test-fnr_mlp))\n",
    "    print(f'FPR={fpr_format}% ({fpr_sign}{fpr_diff_format}%), FNR={fnr_format}% ({fnr_sign}{fnr_diff_format}%)')\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Number of neurons in hidden layer = 8\n",
      "Score=0.9778621125869703, score with default=0.9835547122074636 (-0.005692599620493288)\n",
      "tp=616, fn=27, fp=8, tn=930\n",
      "sensitivity=0.9580093312597201 (-0.01710730948678063), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=4.1991% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 16\n",
      "Score=0.9797596457938014, score with default=0.9835547122074636 (-0.003795066413662229)\n",
      "tp=618, fn=25, fp=7, tn=931\n",
      "sensitivity=0.9611197511664075 (-0.013996889580093264), specificity=0.9925373134328358 (+0.0031982942430703876)\n",
      "FPR=0.7463% (-0.3198%), FNR=3.8880% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 32\n",
      "Score=0.9765970904490828, score with default=0.9835547122074636 (-0.006957621758380772)\n",
      "tp=615, fn=28, fp=9, tn=929\n",
      "sensitivity=0.9564541213063764 (-0.018662519440124314), specificity=0.990405117270789 (+0.0010660980810235365)\n",
      "FPR=0.9595% (-0.1066%), FNR=4.3546% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 40\n",
      "Score=0.9778621125869703, score with default=0.9835547122074636 (-0.005692599620493288)\n",
      "tp=617, fn=26, fp=9, tn=929\n",
      "sensitivity=0.9595645412130638 (-0.015552099533436947), specificity=0.990405117270789 (+0.0010660980810235365)\n",
      "FPR=0.9595% (-0.1066%), FNR=4.0435% (+1.5552%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 50\n",
      "Score=0.9778621125869703, score with default=0.9835547122074636 (-0.005692599620493288)\n",
      "tp=616, fn=27, fp=8, tn=930\n",
      "sensitivity=0.9580093312597201 (-0.01710730948678063), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=4.1991% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 64\n",
      "Score=0.9765970904490828, score with default=0.9835547122074636 (-0.006957621758380772)\n",
      "tp=615, fn=28, fp=9, tn=929\n",
      "sensitivity=0.9564541213063764 (-0.018662519440124314), specificity=0.990405117270789 (+0.0010660980810235365)\n",
      "FPR=0.9595% (-0.1066%), FNR=4.3546% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 100\n",
      "Score=0.978494623655914, score with default=0.9835547122074636 (-0.005060088551549602)\n",
      "tp=617, fn=26, fp=8, tn=930\n",
      "sensitivity=0.9595645412130638 (-0.015552099533436947), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=4.0435% (+1.5552%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 128\n",
      "Score=0.9753320683111955, score with default=0.9835547122074636 (-0.008222643896268145)\n",
      "tp=616, fn=27, fp=12, tn=926\n",
      "sensitivity=0.9580093312597201 (-0.01710730948678063), specificity=0.9872068230277186 (-0.002132196162046851)\n",
      "FPR=1.2793% (+0.2132%), FNR=4.1991% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = 256\n",
      "Score=0.9791271347248577, score with default=0.9835547122074636 (-0.0044275774826059155)\n",
      "tp=619, fn=24, fp=9, tn=929\n",
      "sensitivity=0.9626749611197511 (-0.01244167962674958), specificity=0.990405117270789 (+0.0010660980810235365)\n",
      "FPR=0.9595% (-0.1066%), FNR=3.7325% (+1.2442%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "# learning_rate='adaptive'\n",
    "for i in range(len(hidden_layer_neuron_numbers)):\n",
    "    print('*'*20)\n",
    "    print(f'Number of neurons in hidden layer = {hidden_layer_neuron_numbers[i]}')\n",
    "    mlp_hidden_layer_test = MLPClassifier(random_state=1, max_iter=4000, hidden_layer_sizes=(hidden_layer_neuron_numbers[i]), solver='sgd', learning_rate='adaptive')\n",
    "    mlp_hidden_layer_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_mlp_hidden_layer_test = mlp_hidden_layer_test.predict(X_test_standarized)\n",
    "    mlp_hidden_layer_test_score = mlp_hidden_layer_test.score(X_test_standarized, y_test)\n",
    "    score_sign = '+'\n",
    "    if(mlp_score > mlp_hidden_layer_test_score):\n",
    "        score_sign = '-'\n",
    "    print(f'Score={mlp_hidden_layer_test_score}, score with default={mlp_score} ({score_sign}{abs(mlp_hidden_layer_test_score - mlp_score)})')\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_hidden_layer_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_hidden_layer_test = tp/(tp+fn)\n",
    "    specificity_mlp_hidden_layer_test = tn/(fp+tn)\n",
    "    sensitivity_sign = '+'\n",
    "    if(sensitivity_mlp > sensitivity_mlp_hidden_layer_test):\n",
    "        sensitivity_sign = '-'\n",
    "\n",
    "    specificity_sign = '+'\n",
    "    if(specificity_mlp > specificity_mlp_hidden_layer_test):\n",
    "        specificity_sign = '-'\n",
    "\n",
    "    print(f'sensitivity={sensitivity_mlp_hidden_layer_test} ({sensitivity_sign}{abs(sensitivity_mlp_hidden_layer_test-sensitivity_mlp)}), specificity={specificity_mlp_hidden_layer_test} ({specificity_sign}{abs(specificity_mlp_hidden_layer_test-specificity_mlp)})')\n",
    "    \n",
    "    fpr_mlp_hidden_layer_test = (1-specificity_mlp_hidden_layer_test)*100\n",
    "    fpr_sign = '+'\n",
    "    if(fpr_mlp > fpr_mlp_hidden_layer_test):\n",
    "        fpr_sign = '-'\n",
    "\n",
    "    fnr_mlp_hidden_layer_test  = (1-sensitivity_mlp_hidden_layer_test)*100\n",
    "    fnr_sign='+'\n",
    "    if(fnr_mlp > fnr_mlp_hidden_layer_test):\n",
    "        fnr_sign = '-'\n",
    "\n",
    "    fpr_format = '{:.4f}'.format(fpr_mlp_hidden_layer_test)\n",
    "    fnr_format = '{:.4f}'.format(fnr_mlp_hidden_layer_test)\n",
    "    fpr_diff_format = '{:.4f}'.format(abs(fpr_mlp_hidden_layer_test-fpr_mlp))\n",
    "    fnr_diff_format='{:.4f}'.format(abs(fnr_mlp_hidden_layer_test-fnr_mlp))\n",
    "    print(f'FPR={fpr_format}% ({fpr_sign}{fpr_diff_format}%), FNR={fnr_format}% ({fnr_sign}{fnr_diff_format}%)')\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 layers in hidden layer with sgd solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Number of neurons in hidden layer = (16, 16)\n",
      "Score=0.9797596457938014, score with default=0.9835547122074636 (-0.003795066413662229)\n",
      "tp=619, fn=24, fp=8, tn=930\n",
      "sensitivity=0.9626749611197511 (-0.01244167962674958), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=3.7325% (+1.2442%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = (16, 32)\n",
      "Score=0.9772296015180265, score with default=0.9835547122074636 (-0.006325110689437086)\n",
      "tp=615, fn=28, fp=8, tn=930\n",
      "sensitivity=0.9564541213063764 (-0.018662519440124314), specificity=0.9914712153518124 (+0.002132196162046962)\n",
      "FPR=0.8529% (-0.2132%), FNR=4.3546% (+1.8663%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = (100, 128)\n",
      "Score=0.978494623655914, score with default=0.9835547122074636 (-0.005060088551549602)\n",
      "tp=619, fn=24, fp=10, tn=928\n",
      "sensitivity=0.9626749611197511 (-0.01244167962674958), specificity=0.9893390191897654 (+0.0)\n",
      "FPR=1.0661% (+0.0000%), FNR=3.7325% (+1.2442%)\n",
      "                    \n",
      "********************\n",
      "Number of neurons in hidden layer = (128, 256)\n",
      "Score=0.9759645793801391, score with default=0.9835547122074636 (-0.007590132827324458)\n",
      "tp=618, fn=25, fp=13, tn=925\n",
      "sensitivity=0.9611197511664075 (-0.013996889580093264), specificity=0.9861407249466951 (-0.0031982942430702765)\n",
      "FPR=1.3859% (+0.3198%), FNR=3.8880% (+1.3997%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "# hidden layers\n",
    "# learning_rate = 'adaptive'\n",
    "hidden_layers_neuron_numbers = [(16, 16), (16, 32), (100, 128), (128, 256)]\n",
    "for i in range(len(hidden_layers_neuron_numbers)):\n",
    "    print('*'*20)\n",
    "    print(f'Number of neurons in hidden layer = {hidden_layers_neuron_numbers[i]}')\n",
    "    mlp_hidden_layer_test = MLPClassifier(random_state=1, max_iter=4000, hidden_layer_sizes=(hidden_layers_neuron_numbers[i]), solver='sgd', learning_rate='adaptive')\n",
    "    mlp_hidden_layer_test.fit(X_train_standarized, y_train)\n",
    "    y_prediction_mlp_hidden_layer_test = mlp_hidden_layer_test.predict(X_test_standarized)\n",
    "    mlp_hidden_layer_test_score = mlp_hidden_layer_test.score(X_test_standarized, y_test)\n",
    "    score_sign = '+'\n",
    "    if(mlp_score > mlp_hidden_layer_test_score):\n",
    "        score_sign = '-'\n",
    "    print(f'Score={mlp_hidden_layer_test_score}, score with default={mlp_score} ({score_sign}{abs(mlp_hidden_layer_test_score - mlp_score)})')\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_hidden_layer_test).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_hidden_layer_test = tp/(tp+fn)\n",
    "    specificity_mlp_hidden_layer_test = tn/(fp+tn)\n",
    "    sensitivity_sign = '+'\n",
    "    if(sensitivity_mlp > sensitivity_mlp_hidden_layer_test):\n",
    "        sensitivity_sign = '-'\n",
    "\n",
    "    specificity_sign = '+'\n",
    "    if(specificity_mlp > specificity_mlp_hidden_layer_test):\n",
    "        specificity_sign = '-'\n",
    "\n",
    "    print(f'sensitivity={sensitivity_mlp_hidden_layer_test} ({sensitivity_sign}{abs(sensitivity_mlp_hidden_layer_test-sensitivity_mlp)}), specificity={specificity_mlp_hidden_layer_test} ({specificity_sign}{abs(specificity_mlp_hidden_layer_test-specificity_mlp)})')\n",
    "    \n",
    "    fpr_mlp_hidden_layer_test = (1-specificity_mlp_hidden_layer_test)*100\n",
    "    fpr_sign = '+'\n",
    "    if(fpr_mlp > fpr_mlp_hidden_layer_test):\n",
    "        fpr_sign = '-'\n",
    "\n",
    "    fnr_mlp_hidden_layer_test  = (1-sensitivity_mlp_hidden_layer_test)*100\n",
    "    fnr_sign='+'\n",
    "    if(fnr_mlp > fnr_mlp_hidden_layer_test):\n",
    "        fnr_sign = '-'\n",
    "\n",
    "    fpr_format = '{:.4f}'.format(fpr_mlp_hidden_layer_test)\n",
    "    fnr_format = '{:.4f}'.format(fnr_mlp_hidden_layer_test)\n",
    "    fpr_diff_format = '{:.4f}'.format(abs(fpr_mlp_hidden_layer_test-fpr_mlp))\n",
    "    fnr_diff_format='{:.4f}'.format(abs(fnr_mlp_hidden_layer_test-fnr_mlp))\n",
    "    print(f'FPR={fpr_format}% ({fpr_sign}{fpr_diff_format}%), FNR={fnr_format}% ({fnr_sign}{fnr_diff_format}%)')\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 RFE - Recursive feature elimination\n",
    "Feature ranking with recursive feature elimination.\n",
    "\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4789, 463)\n"
     ]
    }
   ],
   "source": [
    "# data size\n",
    "print(dataFrame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE with Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "n_features=50\n",
      "Score=0.9772296015180265 (+0.0006325110689436864)\n",
      "tp=620, fn=23, fp=13, tn=925\n",
      "sensitivity=96.423% (+0.0%), specificity=98.6141% (+0.1066%)\n",
      "FPR=1.3859% (-0.1066%), FNR=3.577% (+0.0%)\n",
      "                    \n",
      "********************\n",
      "n_features=70\n",
      "Score=0.9759645793801391 (-0.0006325110689436864)\n",
      "tp=622, fn=21, fp=17, tn=921\n",
      "sensitivity=96.7341% (+0.3111%), specificity=98.1876% (-0.3199%)\n",
      "FPR=1.8124% (+0.3199%), FNR=3.2659% (-0.3111%)\n",
      "                    \n",
      "********************\n",
      "n_features=100\n",
      "Score=0.9765970904490828 (+0.0)\n",
      "tp=622, fn=21, fp=16, tn=922\n",
      "sensitivity=96.7341% (+0.3111%), specificity=98.2942% (-0.2133%)\n",
      "FPR=1.7058% (+0.2133%), FNR=3.2659% (-0.3111%)\n",
      "                    \n",
      "********************\n",
      "n_features=150\n",
      "Score=0.9746995572422518 (-0.001897533206831059)\n",
      "tp=622, fn=21, fp=19, tn=919\n",
      "sensitivity=96.7341% (+0.3111%), specificity=97.9744% (-0.5331%)\n",
      "FPR=2.0256% (+0.5331%), FNR=3.2659% (-0.3111%)\n",
      "                    \n",
      "********************\n",
      "n_features=200\n",
      "Score=0.9753320683111955 (-0.0012650221378873727)\n",
      "tp=620, fn=23, fp=16, tn=922\n",
      "sensitivity=96.423% (+0.0%), specificity=98.2942% (-0.2133%)\n",
      "FPR=1.7058% (+0.2133%), FNR=3.577% (+0.0%)\n",
      "                    \n",
      "********************\n",
      "n_features=300\n",
      "Score=0.9759645793801391 (-0.0006325110689436864)\n",
      "tp=622, fn=21, fp=17, tn=921\n",
      "sensitivity=96.7341% (+0.3111%), specificity=98.1876% (-0.3199%)\n",
      "FPR=1.8124% (+0.3199%), FNR=3.2659% (-0.3111%)\n",
      "                    \n",
      "********************\n",
      "n_features=400\n",
      "Score=0.9753320683111955 (-0.0012650221378873727)\n",
      "tp=620, fn=23, fp=16, tn=922\n",
      "sensitivity=96.423% (+0.0%), specificity=98.2942% (-0.2133%)\n",
      "FPR=1.7058% (+0.2133%), FNR=3.577% (+0.0%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "# take 200 most informative features\n",
    "n_features_list = [50, 70, 100, 150, 200, 300, 400]\n",
    "\n",
    "for n_features in n_features_list:\n",
    "    print('*'*20)\n",
    "    print(f'n_features={n_features}')\n",
    "    \n",
    "    # decision tree\n",
    "    decisionTree_with_rfe = DecisionTreeClassifier()\n",
    "    rfe = RFE(estimator=decisionTree_with_rfe, n_features_to_select=n_features, step=10)\n",
    "    rfe = rfe.fit(X_train_standarized, y_train)\n",
    "    y_prediction_rfe = rfe.predict(X_test_standarized)\n",
    "\n",
    "    # compare score\n",
    "    decisionTree_with_rfe_score = rfe.score(X_test_standarized, y_test)\n",
    "    decisionTree_score_diff = decisionTree_with_rfe_score - decision_tree_score\n",
    "    print(f'Score={decisionTree_with_rfe_score} ({decisionTree_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_rfe).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_dt_rfe = round(100*tp/(tp+fn), 4)\n",
    "    specificity_dt_rfe = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_dt_diff = round(sensitivity_dt_rfe - sensitivity_dt, 4)\n",
    "    specificity_dt_diff = round(specificity_dt_rfe - specificity_dt, 4)\n",
    "    print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_rfe, sensitivity_dt_diff, specificity_dt_rfe, specificity_dt_diff))\n",
    "\n",
    "    fpr_dt_rfe = round(100-specificity_dt_rfe, 4)\n",
    "    fnr_dt_rfe = round(100-sensitivity_dt_rfe, 4)\n",
    "    fpr_dt_diff = round(fpr_dt_rfe - fpr_dt, 4)\n",
    "    fnr_dt_diff = round(fnr_dt_rfe - fnr_dt, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_rfe, fpr_dt_diff, fnr_dt_rfe, fnr_dt_diff))\n",
    "    print(' '*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Univariate feature selection - SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestFeaturesList = [50, 70, 100, 150, 200, 300, 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Best features=50\n",
      "Score=0.9778621125869703 (-0.006957621758380772)\n",
      "tp=620, fn=23, fp=12, tn=926\n",
      "sensitivity=0.9642 (-0.0125), specificity=0.9872 (-0.0032)\n",
      "FPR=1.28% (+0.32%), FNR=3.58% (+1.25%)\n",
      "                    \n",
      "********************\n",
      "Best features=70\n",
      "Score=0.9860847564832385 (+0.0012650221378873727)\n",
      "tp=624, fn=19, fp=3, tn=935\n",
      "sensitivity=0.9705 (-0.0062), specificity=0.9968 (+0.0064)\n",
      "FPR=0.32% (-0.64%), FNR=2.95% (+0.62%)\n",
      "                    \n",
      "********************\n",
      "Best features=100\n",
      "Score=0.9816571790006325 (-0.003162555344718543)\n",
      "tp=623, fn=20, fp=9, tn=929\n",
      "sensitivity=0.9689 (-0.0078), specificity=0.9904 (+0.0)\n",
      "FPR=0.96% (+0.0%), FNR=3.11% (+0.78%)\n",
      "                    \n",
      "********************\n",
      "Best features=150\n",
      "Score=0.9816571790006325 (-0.003162555344718543)\n",
      "tp=622, fn=21, fp=8, tn=930\n",
      "sensitivity=0.9673 (-0.0094), specificity=0.9915 (+0.0011)\n",
      "FPR=0.85% (-0.11%), FNR=3.27% (+0.94%)\n",
      "                    \n",
      "********************\n",
      "Best features=200\n",
      "Score=0.9810246679316889 (-0.003795066413662229)\n",
      "tp=626, fn=17, fp=13, tn=925\n",
      "sensitivity=0.9736 (-0.0031), specificity=0.9861 (-0.0043)\n",
      "FPR=1.39% (+0.43%), FNR=2.64% (+0.31%)\n",
      "                    \n",
      "********************\n",
      "Best features=300\n",
      "Score=0.978494623655914 (-0.006325110689437086)\n",
      "tp=625, fn=18, fp=16, tn=922\n",
      "sensitivity=0.972 (-0.0047), specificity=0.9829 (-0.0075)\n",
      "FPR=1.71% (+0.75%), FNR=2.8% (+0.47%)\n",
      "                    \n",
      "********************\n",
      "Best features=400\n",
      "Score=0.9791271347248577 (-0.005692599620493399)\n",
      "tp=619, fn=24, fp=9, tn=929\n",
      "sensitivity=0.9627 (-0.014), specificity=0.9904 (+0.0)\n",
      "FPR=0.96% (+0.0%), FNR=3.73% (+1.4%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for bestFeatures in bestFeaturesList:\n",
    "    print('*'*20)\n",
    "    print(f'Best features={bestFeatures}')\n",
    "    selector = SelectKBest(chi2, k=bestFeatures)\n",
    "    X_train_skb = selector.fit_transform(X_train, y_train) # fit only on train set!\n",
    "    X_test_skb = selector.transform(X_test)\n",
    "\n",
    "    # standarization\n",
    "    scaler = StandardScaler().fit(X_train_skb) # fit only on train set!\n",
    "    X_train_skb_std = scaler.transform(X_train_skb)\n",
    "    X_test_skb_std = scaler.transform(X_test_skb)\n",
    "\n",
    "    # mlp classifier\n",
    "    mlp_skb = MLPClassifier(random_state=1, max_iter=300, solver='adam')\n",
    "    mlp_skb.fit(X_train_skb_std, y_train)\n",
    "    y_prediction_mlp_skb = mlp_skb.predict(X_test_skb_std)\n",
    "    mlp_skb_score = mlp_skb.score(X_test_skb_std, y_test)\n",
    "\n",
    "    # compare score with default\n",
    "    mlp_skb_diff = mlp_skb_score - mlp_score\n",
    "    print(f'Score={mlp_skb_score} ({mlp_skb_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_skb).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_skb = round(tp/(tp+fn), 4)\n",
    "    specificity_mlp_skb = round(tn/(fp+tn), 4)\n",
    "    \n",
    "    # compare with default\n",
    "    sensitivity_mlp_diff = round(sensitivity_mlp_skb-sensitivity_mlp, 4)\n",
    "    specificity_mlp_diff = round(specificity_mlp_skb-specificity_mlp, 4)\n",
    "    print(\"sensitivity={} ({:+}), specificity={} ({:+})\".format(sensitivity_mlp_skb, sensitivity_mlp_diff, specificity_mlp_skb, specificity_mlp_diff))\n",
    "\n",
    "    # fpr and fnr\n",
    "    fpr_mlp_skb = round((1-specificity_mlp_skb)*100, 4)\n",
    "    fnr_mlp_skb = round((1-sensitivity_mlp_skb)*100, 4)\n",
    "    fpr_mlp_skb_diff = round(fpr_mlp_skb - fpr_mlp, 4)\n",
    "    fnr_mlp_skb_diff = round(fnr_mlp_skb - fnr_mlp, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_skb, fpr_mlp_skb_diff, fnr_mlp_skb, fnr_mlp_skb_diff))\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results for selecting 70 features. FPR has been reduced to 0.32% (less than 0.5%), at the same time FNR was increased by 0.6172% making it to 2.95%. We accept more spam (sensitivity is lower = 97.05%) but we take more valid mails (specificity = 99.68%).\n",
    "\n",
    "* Best features=70\n",
    "* Score=0.9860847564832385 (+0.0013)\n",
    "* tp=624, fn=19, fp=3, tn=935\n",
    "* sensitivity=0.9705 (-0.0062), specificity=0.9968 (+0.0064)\n",
    "* FPR=0.32% (-0.6395%), FNR=2.95% (+0.6172%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest with DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest with DecisionTree\n",
      "********************\n",
      "Best features=50\n",
      "Score=0.9721695129664769 (-0.0044275774826059155)\n",
      "tp=608, fn=35, fp=9, tn=929\n",
      "sensitivity=94.5568% (-1.8662%), specificity=99.0405% (+0.533%)\n",
      "FPR=0.9595% (-0.533%), FNR=5.4432% (+1.8662%)\n",
      "                    \n",
      "********************\n",
      "Best features=70\n",
      "Score=0.9746995572422518 (-0.001897533206831059)\n",
      "tp=608, fn=35, fp=5, tn=933\n",
      "sensitivity=94.5568% (-1.8662%), specificity=99.467% (+0.9595%)\n",
      "FPR=0.533% (-0.9595%), FNR=5.4432% (+1.8662%)\n",
      "                    \n",
      "********************\n",
      "Best features=100\n",
      "Score=0.9715370018975332 (-0.005060088551549602)\n",
      "tp=608, fn=35, fp=10, tn=928\n",
      "sensitivity=94.5568% (-1.8662%), specificity=98.9339% (+0.4264%)\n",
      "FPR=1.0661% (-0.4264%), FNR=5.4432% (+1.8662%)\n",
      "                    \n",
      "********************\n",
      "Best features=150\n",
      "Score=0.9709044908285895 (-0.005692599620493288)\n",
      "tp=609, fn=34, fp=12, tn=926\n",
      "sensitivity=94.7123% (-1.7107%), specificity=98.7207% (+0.2132%)\n",
      "FPR=1.2793% (-0.2132%), FNR=5.2877% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Best features=200\n",
      "Score=0.9746995572422518 (-0.001897533206831059)\n",
      "tp=621, fn=22, fp=18, tn=920\n",
      "sensitivity=96.5785% (+0.1555%), specificity=98.081% (-0.4265%)\n",
      "FPR=1.919% (+0.4265%), FNR=3.4215% (-0.1555%)\n",
      "                    \n",
      "********************\n",
      "Best features=300\n",
      "Score=0.9746995572422518 (-0.001897533206831059)\n",
      "tp=617, fn=26, fp=14, tn=924\n",
      "sensitivity=95.9565% (-0.4665%), specificity=98.5075% (+0.0%)\n",
      "FPR=1.4925% (+0.0%), FNR=4.0435% (+0.4665%)\n",
      "                    \n",
      "********************\n",
      "Best features=400\n",
      "Score=0.9715370018975332 (-0.005060088551549602)\n",
      "tp=612, fn=31, fp=14, tn=924\n",
      "sensitivity=95.1788% (-1.2442%), specificity=98.5075% (+0.0%)\n",
      "FPR=1.4925% (+0.0%), FNR=4.8212% (+1.2442%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "print('SelectKBest with DecisionTree')\n",
    "for bestFeatures in bestFeaturesList:\n",
    "    print('*'*20)\n",
    "    print(f'Best features={bestFeatures}')\n",
    "    selector = SelectKBest(chi2, k=bestFeatures)\n",
    "    X_train_skb = selector.fit_transform(X_train, y_train) # fit only on train set!\n",
    "    X_test_skb = selector.transform(X_test)\n",
    "\n",
    "    # standarization\n",
    "    scaler = StandardScaler().fit(X_train_skb) # fit only on train set!\n",
    "    X_train_skb_std = scaler.transform(X_train_skb)\n",
    "    X_test_skb_std = scaler.transform(X_test_skb)\n",
    "\n",
    "    # decision tree classifier\n",
    "    dt_skb = DecisionTreeClassifier()\n",
    "    dt_skb.fit(X_train_skb_std, y_train)\n",
    "    y_prediction_dt_skb = dt_skb.predict(X_test_skb_std)\n",
    "    dt_skb_score = dt_skb.score(X_test_skb_std, y_test)\n",
    "\n",
    "    # compare score with default\n",
    "    dt_skb_diff = dt_skb_score - decision_tree_score\n",
    "    print(f'Score={dt_skb_score} ({dt_skb_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_dt_skb).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_dt_skb = round(100*tp/(tp+fn), 4)\n",
    "    specificity_dt_skb = round(100*tn/(fp+tn), 4)\n",
    "    \n",
    "    # compare with default\n",
    "    sensitivity_dt_diff = round(sensitivity_dt_skb-sensitivity_dt, 4)\n",
    "    specificity_dt_diff = round(specificity_dt_skb-specificity_dt, 4)\n",
    "    print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_skb, sensitivity_dt_diff, specificity_dt_skb, specificity_dt_diff))\n",
    "\n",
    "    # fpr and fnr\n",
    "    fpr_dt_skb = round(100-specificity_dt_skb, 4)\n",
    "    fnr_dt_skb = round(100-sensitivity_dt_skb, 4)\n",
    "    fpr_dt_skb_diff = round(fpr_dt_skb - fpr_dt, 4)\n",
    "    fnr_dt_skb_diff = round(fnr_dt_skb - fnr_dt, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_skb, fpr_dt_skb_diff, fnr_dt_skb, fnr_dt_skb_diff))\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA).\n",
    "\n",
    "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "componentsList = [50, 70, 100, 150, 200, 300, 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA with MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Components=50\n",
      "Score=0.9835547122074636 (-0.0012650221378874837)\n",
      "tp=623, fn=20, fp=6, tn=932\n",
      "sensitivity=0.9689 (-0.0078), specificity=0.9936 (+0.0032)\n",
      "FPR=0.64% (-0.32%), FNR=3.11% (+0.78%)\n",
      "                    \n",
      "********************\n",
      "Components=70\n",
      "Score=0.9835547122074636 (-0.0012650221378874837)\n",
      "tp=623, fn=20, fp=6, tn=932\n",
      "sensitivity=0.9689 (-0.0078), specificity=0.9936 (+0.0032)\n",
      "FPR=0.64% (-0.32%), FNR=3.11% (+0.78%)\n",
      "                    \n",
      "********************\n",
      "Components=100\n",
      "Score=0.9803921568627451 (-0.004427577482606027)\n",
      "tp=620, fn=23, fp=8, tn=930\n",
      "sensitivity=0.9642 (-0.0125), specificity=0.9915 (+0.0011)\n",
      "FPR=0.85% (-0.11%), FNR=3.58% (+1.25%)\n",
      "                    \n",
      "********************\n",
      "Components=150\n",
      "Score=0.9778621125869703 (-0.006957621758380772)\n",
      "tp=617, fn=26, fp=9, tn=929\n",
      "sensitivity=0.9596 (-0.0171), specificity=0.9904 (+0.0)\n",
      "FPR=0.96% (+0.0%), FNR=4.04% (+1.71%)\n",
      "                    \n",
      "********************\n",
      "Components=200\n",
      "Score=0.9829222011385199 (-0.00189753320683117)\n",
      "tp=622, fn=21, fp=6, tn=932\n",
      "sensitivity=0.9673 (-0.0094), specificity=0.9936 (+0.0032)\n",
      "FPR=0.64% (-0.32%), FNR=3.27% (+0.94%)\n",
      "                    \n",
      "********************\n",
      "Components=300\n",
      "Score=0.9734345351043643 (-0.011385199240986799)\n",
      "tp=607, fn=36, fp=6, tn=932\n",
      "sensitivity=0.944 (-0.0327), specificity=0.9936 (+0.0032)\n",
      "FPR=0.64% (-0.32%), FNR=5.6% (+3.27%)\n",
      "                    \n",
      "********************\n",
      "Components=400\n",
      "Score=0.9753320683111955 (-0.009487666034155628)\n",
      "tp=614, fn=29, fp=10, tn=928\n",
      "sensitivity=0.9549 (-0.0218), specificity=0.9893 (-0.0011)\n",
      "FPR=1.07% (+0.11%), FNR=4.51% (+2.18%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for components in componentsList:\n",
    "    print('*'*20)\n",
    "    print(f'Components={components}')\n",
    "    pca = PCA(n_components=components).fit(X_train) # fit only on train set\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # standarize\n",
    "    scaler = StandardScaler().fit(X_train_pca)\n",
    "    X_train_pca_std = scaler.transform(X_train_pca)\n",
    "    X_test_pca_std = scaler.transform(X_test_pca)\n",
    "\n",
    "    # mlp\n",
    "    mlp_pca = MLPClassifier(random_state=1, max_iter=300, solver='adam')\n",
    "    mlp_pca.fit(X_train_pca_std, y_train)\n",
    "    y_prediction_mlp_pca = mlp_pca.predict(X_test_pca_std)\n",
    "    mlp_pca_score = mlp_pca.score(X_test_pca_std, y_test)\n",
    "    \n",
    "    # compare with default\n",
    "    mlp_pca_score_diff = mlp_pca_score - mlp_score\n",
    "    print(f'Score={mlp_pca_score} ({mlp_pca_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_pca).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_mlp_pca = round(tp/(tp+fn), 4)\n",
    "    specificity_mlp_pca = round(tn/(fp+tn), 4)\n",
    "    sensitivity_mlp_diff = round(sensitivity_mlp_pca - sensitivity_mlp, 4)\n",
    "    specificity_mlp_diff = round(specificity_mlp_pca - specificity_mlp, 4)\n",
    "    print(\"sensitivity={} ({:+}), specificity={} ({:+})\".format(sensitivity_mlp_pca, sensitivity_mlp_diff, specificity_mlp_pca, specificity_mlp_diff))\n",
    "\n",
    "    # fpr and fnr\n",
    "    fpr_mlp_pca = round((1-specificity_mlp_pca)*100, 4)\n",
    "    fnr_mlp_pca = round((1-sensitivity_mlp_pca)*100, 4)\n",
    "    fpr_mlp_diff = round(fpr_mlp_pca - fpr_mlp, 4)\n",
    "    fnr_mlp_diff = round(fnr_mlp_pca - fnr_mlp, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp_pca, fpr_mlp_diff, fnr_mlp_pca, fnr_mlp_diff))\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA with Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Components=50\n",
      "Score=0.9645793801391525 (-0.012017710309930374)\n",
      "tp=615, fn=28, fp=28, tn=910\n",
      "sensitivity=95.6454% (-0.7776%), specificity=97.0149% (-1.4926%)\n",
      "FPR=2.9851% (+1.4926%), FNR=4.3546% (+0.7776%)\n",
      "                    \n",
      "********************\n",
      "Components=70\n",
      "Score=0.9652118912080961 (-0.011385199240986688)\n",
      "tp=617, fn=26, fp=29, tn=909\n",
      "sensitivity=95.9565% (-0.4665%), specificity=96.9083% (-1.5992%)\n",
      "FPR=3.0917% (+1.5992%), FNR=4.0435% (+0.4665%)\n",
      "                    \n",
      "********************\n",
      "Components=100\n",
      "Score=0.9601518026565465 (-0.01644528779253629)\n",
      "tp=609, fn=34, fp=29, tn=909\n",
      "sensitivity=94.7123% (-1.7107%), specificity=96.9083% (-1.5992%)\n",
      "FPR=3.0917% (+1.5992%), FNR=5.2877% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Components=150\n",
      "Score=0.9690069576217584 (-0.007590132827324458)\n",
      "tp=609, fn=34, fp=15, tn=923\n",
      "sensitivity=94.7123% (-1.7107%), specificity=98.4009% (-0.1066%)\n",
      "FPR=1.5991% (+0.1066%), FNR=5.2877% (+1.7107%)\n",
      "                    \n",
      "********************\n",
      "Components=200\n",
      "Score=0.9639468690702088 (-0.01265022137887406)\n",
      "tp=611, fn=32, fp=25, tn=913\n",
      "sensitivity=95.0233% (-1.3997%), specificity=97.3348% (-1.1727%)\n",
      "FPR=2.6652% (+1.1727%), FNR=4.9767% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Components=300\n",
      "Score=0.9645793801391525 (-0.012017710309930374)\n",
      "tp=611, fn=32, fp=24, tn=914\n",
      "sensitivity=95.0233% (-1.3997%), specificity=97.4414% (-1.0661%)\n",
      "FPR=2.5586% (+1.0661%), FNR=4.9767% (+1.3997%)\n",
      "                    \n",
      "********************\n",
      "Components=400\n",
      "Score=0.9658444022770398 (-0.010752688172043001)\n",
      "tp=612, fn=31, fp=23, tn=915\n",
      "sensitivity=95.1788% (-1.2442%), specificity=97.548% (-0.9595%)\n",
      "FPR=2.452% (+0.9595%), FNR=4.8212% (+1.2442%)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for components in componentsList:\n",
    "    print('*'*20)\n",
    "    print(f'Components={components}')\n",
    "    pca = PCA(n_components=components).fit(X_train) # fit only on train set\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # standarize\n",
    "    scaler = StandardScaler().fit(X_train_pca)\n",
    "    X_train_pca_std = scaler.transform(X_train_pca)\n",
    "    X_test_pca_std = scaler.transform(X_test_pca)\n",
    "\n",
    "    # decision tree classifier\n",
    "    dt_pca = DecisionTreeClassifier()\n",
    "    dt_pca.fit(X_train_pca_std, y_train)\n",
    "    y_prediction_dt_pca = dt_pca.predict(X_test_pca_std)\n",
    "    dt_pca_score = dt_pca.score(X_test_pca_std, y_test)\n",
    "    \n",
    "    # compare with default\n",
    "    dt_pca_score_diff = dt_pca_score - decision_tree_score\n",
    "    print(f'Score={dt_pca_score} ({dt_pca_score_diff:+})')\n",
    "\n",
    "    # confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_dt_pca).ravel()\n",
    "    print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "    sensitivity_dt_pca = round(100*tp/(tp+fn), 4)\n",
    "    specificity_dt_pca = round(100*tn/(fp+tn), 4)\n",
    "    sensitivity_dt_diff = round(sensitivity_dt_pca - sensitivity_dt, 4)\n",
    "    specificity_dt_diff = round(specificity_dt_pca - specificity_dt, 4)\n",
    "    print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_pca, sensitivity_dt_diff, specificity_dt_pca, specificity_dt_diff))\n",
    "\n",
    "    # fpr and fnr\n",
    "    fpr_dt_pca = round(100-specificity_dt_pca, 4)\n",
    "    fnr_dt_pca = round(100-sensitivity_dt_pca, 4)\n",
    "    fpr_dt_diff = round(fpr_dt_pca - fpr_dt, 4)\n",
    "    fnr_dt_diff = round(fnr_dt_pca - fnr_dt, 4)\n",
    "    print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_pca, fpr_dt_diff, fnr_dt_pca, fnr_dt_diff))\n",
    "    print(' '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methods for class-imbalanced problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to perform over-sampling using SMOTE - Synthetic Minority over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train dataset shape: Counter({'no': 2011, 'yes': 1197})\n"
     ]
    }
   ],
   "source": [
    "print(f'Original train dataset shape: {Counter(y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that originally train set contains more non spam data. SMOTE algorithm will add spam samples to train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled train dataset shape: Counter({'yes': 2011, 'no': 2011})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "print(f'Resampled train dataset shape: {Counter(y_train_res)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how it affects sensitivity and specificity on MLP and DecisionTree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarization\n",
    "scaler = StandardScaler().fit(X_train_res, y_train_res)\n",
    "X_train_res_std = scaler.transform(X_train_res)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9740670461733081 (-0.010752688172043001)\n",
      "tp=621, fn=22, fp=19, tn=919\n",
      "sensitivity=96.5785% (-1.0887%), specificity=97.9744% (-1.0661%)\n",
      "FPR=0.9595% (+1.0661%), FNR=2.3328% (+1.0887%)\n"
     ]
    }
   ],
   "source": [
    "# mlp classifier\n",
    "mlp_smote = MLPClassifier(random_state=1, max_iter=300, solver='adam')\n",
    "mlp_smote.fit(X_train_res_std, y_train_res)\n",
    "y_prediction_mlp_smote = mlp_smote.predict(X_test_std)\n",
    "mlp_smote_score = mlp_smote.score(X_test_std, y_test)\n",
    "mlp_score_diff = mlp_smote_score - mlp_score\n",
    "print(f'Score={mlp_smote_score} ({mlp_score_diff:+})')\n",
    "\n",
    "# confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_mlp_smote).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "\n",
    "sensitivity_mlp_smote = round(100*tp/(tp+fn), 4)\n",
    "specificity_mlp_smote = round(100*tn/(fp+tn), 4)\n",
    "sensitivity_mlp_diff = round(sensitivity_mlp_smote - sensitivity_mlp, 4)\n",
    "specificity_mlp_diff = round(specificity_mlp_smote - specificity_mlp, 4)\n",
    "\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_mlp_smote, sensitivity_mlp_diff, specificity_mlp_smote, specificity_mlp_diff))\n",
    "\n",
    "fpr_mlp_smote = round(100-specificity_mlp_smote, 4)\n",
    "fnr_mlp_smote = round(100-sensitivity_mlp_smote, 4)\n",
    "fpr_mlp_diff = round(fpr_mlp_smote - fpr_mlp, 4)\n",
    "fnr_mlp_diff = round(fnr_mlp_smote - fnr_mlp, 4)\n",
    "print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_mlp, fpr_mlp_diff, fnr_mlp, fnr_mlp_diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=0.9601518026565465 (-0.017077798861479976)\n",
      "tp=609, fn=34, fp=29, tn=909\n",
      "sensitivity=94.7123% (-2.1773%), specificity=96.9083% (-1.3859%)\n",
      "FPR=3.0917% (+1.3859%), FNR=5.2877% (+2.1773%)\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "dt_smote = DecisionTreeClassifier()\n",
    "dt_smote.fit(X_train_res_std, y_train_res)\n",
    "y_prediction_dt_smote = dt_smote.predict(X_test_std)\n",
    "dt_smote_score = dt_smote.score(X_test_std, y_test)\n",
    "dt_score_diff = dt_smote_score - decision_tree_score\n",
    "print(f'Score={dt_smote_score} ({dt_score_diff:+})')\n",
    "\n",
    "# confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_prediction_dt_smote).ravel()\n",
    "print(f'tp={tp}, fn={fn}, fp={fp}, tn={tn}')\n",
    "\n",
    "sensitivity_dt_smote = round(100*tp/(tp+fn), 4)\n",
    "specificity_dt_smote = round(100*tn/(fp+tn), 4)\n",
    "sensitivity_dt_diff = round(sensitivity_dt_smote - sensitivity_dt, 4)\n",
    "specificity_dt_diff = round(specificity_dt_smote - specificity_dt, 4)\n",
    "\n",
    "print(\"sensitivity={}% ({:+}%), specificity={}% ({:+}%)\".format(sensitivity_dt_smote, sensitivity_dt_diff, specificity_dt_smote, specificity_dt_diff))\n",
    "\n",
    "fpr_dt_smote = round(100-specificity_dt_smote, 4)\n",
    "fnr_dt_smote = round(100-sensitivity_dt_smote, 4)\n",
    "fpr_dt_diff = round(fpr_dt_smote - fpr_dt, 4)\n",
    "fnr_dt_diff = round(fnr_dt_smote - fnr_dt, 4)\n",
    "print(\"FPR={}% ({:+}%), FNR={}% ({:+}%)\".format(fpr_dt_smote, fpr_dt_diff, fnr_dt_smote, fnr_dt_diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. The use of asymetric error costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ensamble learning"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "160a8e799b4c8ac5e6b5e507c10561fe57290204298c2a882096e26ea13919e6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
